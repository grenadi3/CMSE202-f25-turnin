{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37abd0c1-f3bc-4c91-80b2-3b14f385ef97",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "# Perceptron, SVM, and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41a524-ade8-4277-bffc-7547379f9d22",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: right;\"> &#9989; Eric Grenadier</p>\n",
    "# <p style=\"text-align: right;\"> &#9989; grenadi3</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e13b3-c564-4b25-9e3f-8bef7e3cd6e3",
   "metadata": {},
   "source": [
    "# Goal for this homework assignment\n",
    "We have worked some basics on perceptron, SVM, and PCA in the pre-class and in-class assignments. In this homework assignment, we will:\n",
    "\n",
    "* Continue to use git as the version control tool\n",
    "* Work on unfamiliar data\n",
    "* Use perceptron to classify data \n",
    "* Use SVM to classify data\n",
    "* Use principal component analysis to facilitate classification\n",
    "\n",
    "\n",
    "**This assignment is due by 11:59 pm on Friday, April 25th. Note that ONLY the copy on GITHUB will be graded.**  **There are 60 standard points possible in this assignment including points for Git commits/pushes. The distribution of points can be found in the section headers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199515ba-e709-40e2-a189-5da69a6f1699",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Git repository (6 points)\n",
    "\n",
    "You're going to add this assignment to the `cmse202-s25-turnin` repository you previously created. The history of progress on the assignment will be tracked via git commitments. \n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-s25-turnin` **local** repository and create a new directory called `hw-04`\n",
    "\n",
    "2. Move this notebook into that **new directory** in your repository. \n",
    "\n",
    "5. Double check to make sure your file is at the correct directory.\n",
    "\n",
    "6. Once you're certain that file and directory are correct, add this notebook to your repository, then make a commit and push it to GitHub. You may need to use `git push origin hw04` to push your file to GitHub.\n",
    "\n",
    "Finally, &#9989; **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below. **Points for this part will be given for correctly setting up branch, etc., above, and for doing git commits/pushes mentioned throughout the assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e549e-214b-4858-930f-e2b7c9015580",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> git clone https://github.com/grenadi3/CMSE202-f25-turnin.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e93e6e-2297-490f-b1c8-a87bbd9d4814",
   "metadata": {},
   "source": [
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" repository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s25-turnin`\" repository inside the `hw-04` directory that you just created.\n",
    "\n",
    "Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the problems for a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2cd6e-5eac-4817-afad-c1d8ab86214b",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Deal with unfamiliar data (35 points)\n",
    "\n",
    "## Warm up with perceptron for binary classification\n",
    "## 2.1 Load up the dataset\n",
    "\n",
    "This data is obtained from Kaggle/diabetes. It contains multiple measured values and a label for whether the patient is diagnosed as diabetic. \n",
    "\n",
    "* Use commands to dowdload the dataset from `https://raw.githubusercontent.com/huichiayu/cmse202-s25-supllemental_data/refs/heads/main/HW04/diabetes_prediction_dataset.csv`\n",
    "* Use Pandas to load in the data and briefly examine it.\n",
    "* Succeed data load-up gets **2 pt**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8dde6c3-799e-480b-ac67-a8e0d2716b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
       "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac61eaf-8d5a-4889-8c9a-624aeefc511d",
   "metadata": {},
   "source": [
    "How many patients are in this dataset? What are features of the patients?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc156a61-260e-401d-a92d-d80a0016be0b",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> 1000 patients, columns are ['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
    "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0e656-57ad-4757-b1c5-fa51c9aef9f9",
   "metadata": {},
   "source": [
    "### Use your perceptron class built in Day18 and Day19 assignments to classify whether patients are diabetic.\n",
    "\n",
    "* You should see that there are some features that are non-numerics.\n",
    "* The first one is `gender`. Find the types of classes and convert them to numerics in your dataframe.\n",
    "* The second one is `smoking_history`, convert those string labels to numerics.\n",
    "* Note that since perceptron is a binary classifier, which only determines which side of the dividing line the data points reside, we should also convert the labels to `+1` and `-1`.\n",
    "* Completing data conversion gets **5 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af4a995-58a7-4478-9e3e-b805ab21779f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                   int64\n",
       "age                    float64\n",
       "hypertension             int64\n",
       "heart_disease            int64\n",
       "smoking_history        float64\n",
       "bmi                    float64\n",
       "HbA1c_level            float64\n",
       "blood_glucose_level      int64\n",
       "diabetes                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'] = (df['gender'] == 'male').astype(int)\n",
    "df['smoking_history'] = df['smoking_history'].map({'never': 0, 'current': 1, 'No Info': 2})\n",
    "df['diabetes'] = df['diabetes'].map({0: -1, 1: 1})\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2245b-3a9e-4b17-a5e3-b2d8365034db",
   "metadata": {},
   "source": [
    "### Now all feature varilables are numerics.\n",
    "\n",
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 Binary perceptron classifier\n",
    "\n",
    "Copy your perceptron class to the cell below. \n",
    "\n",
    "* DO NOT use the one from statsmodel. We want to test the perceptron you built.\n",
    "* Note that your predict method should output `+1` or `-1` for positive or negative values, respectively.\n",
    "* A functional perceptron classifier gets **4 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f7672c-5fc3-4c4f-8d06-ec88508c81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random # Needed for shuffling in Perceptron\n",
    "\n",
    "# --- Paste the refined Perceptron Class Code Here ---\n",
    "# (Make sure the class definition from the previous answer is included)\n",
    "class Perceptron():\n",
    "    \"\"\"\n",
    "    A simple implementation of the Perceptron algorithm for binary classification.\n",
    "\n",
    "    Attributes:\n",
    "        iterations (int): The number of passes over the training dataset.\n",
    "        learning_rate (float): The step size for weight updates.\n",
    "        weights (np.ndarray): The learned weights (including the bias term at index 0).\n",
    "        data (np.ndarray): The training data stored internally (used only during fit).\n",
    "        errors_ (list): Stores the number of misclassifications per epoch during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, iterations=100, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Initializes the Perceptron classifier hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            iterations (int): Maximum number of training iterations (epochs).\n",
    "            learning_rate (float): The learning rate (eta).\n",
    "        \"\"\"\n",
    "        # Initialize weights later in fit() once data dimension is known\n",
    "        self.weights = None\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.errors_ = [] # To store number of misclassifications per epoch\n",
    "\n",
    "    def _initialize_weights(self, num_features):\n",
    "         \"\"\"Initializes weights to zeros based on number of features.\"\"\"\n",
    "         self.weights = np.zeros(num_features + 1) # +1 for bias\n",
    "\n",
    "    def predict(self, feature_set):\n",
    "        if self.weights is None:\n",
    "            raise RuntimeError(\"Perceptron must be trained before prediction.\")\n",
    "\n",
    "        features = np.asarray(feature_set)\n",
    "        # Calculate activation: w0 + w1*x1 + w2*x2 + ...\n",
    "        activation = self.weights[0] + np.dot(features, self.weights[1:])\n",
    "        # Return +1 if activation >= 0, else -1 (step function)\n",
    "        return 1 if activation >= 0 else -1\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Trains the Perceptron model on the provided training data.\n",
    "\n",
    "        Args:\n",
    "            X_train (np.ndarray): Training features (samples x features).\n",
    "            y_train (np.ndarray): Training labels (samples x 1).\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X_train.shape\n",
    "\n",
    "        # Initialize weights based on training data dimensions\n",
    "        self._initialize_weights(n_features)\n",
    "\n",
    "        # Verify labels are -1 and 1\n",
    "        unique_labels = np.unique(y_train)\n",
    "        if not (len(unique_labels) == 2 and np.all(np.isin(unique_labels, [-1, 1]))):\n",
    "             raise ValueError(\"Training labels must be exactly -1 and 1.\")\n",
    "\n",
    "        # Combine features and labels for easier iteration during training\n",
    "        training_data = np.hstack((X_train, y_train.reshape(-1, 1)))\n",
    "\n",
    "        self.errors_ = [] # Reset errors history\n",
    "        for epoch in range(self.iterations):\n",
    "            errors_in_epoch = 0\n",
    "            # Shuffle data each epoch to avoid cycles\n",
    "            np.random.shuffle(training_data)\n",
    "\n",
    "            for sample in training_data:\n",
    "                features = sample[:-1]\n",
    "                target = sample[-1]\n",
    "                prediction = self.predict(features) # Use internal predict\n",
    "\n",
    "                # If prediction is wrong, update weights\n",
    "                if prediction != target:\n",
    "                    # Standard Perceptron update rule: w = w + learning_rate * target * x\n",
    "                    update = self.learning_rate * target\n",
    "                    self.weights[1:] += update * features # Update feature weights (w1, w2, ...)\n",
    "                    self.weights[0] += update             # Update bias weight (w0)\n",
    "                    errors_in_epoch += 1\n",
    "\n",
    "            self.errors_.append(errors_in_epoch)\n",
    "            # Optional: Stopping condition\n",
    "            # if errors_in_epoch == 0:\n",
    "            #     print(f\"Converged after {epoch+1} epochs.\")\n",
    "            #     break\n",
    "\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"Calculates accuracy on the test set.\"\"\"\n",
    "        y_pred = np.array([self.predict(xi) for xi in X_test])\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    def plot_decision_boundary(self, X, y):\n",
    "        \"\"\"\n",
    "        Plots the data points and the decision boundary learned by the Perceptron.\n",
    "        Assumes the data has exactly 2 features.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Features (samples x features).\n",
    "            y (np.ndarray): Labels (samples x 1).\n",
    "        \"\"\"\n",
    "        if self.weights is None:\n",
    "             raise RuntimeError(\"Perceptron must be trained before plotting.\")\n",
    "        if X.shape[1] != 2:\n",
    "            print(\"Warning: Plotting decision boundary only implemented for 2 features.\")\n",
    "            return\n",
    "\n",
    "        w0, w1, w2 = self.weights  # Bias, weight_feature1, weight_feature2\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1],\n",
    "                    c='blue', marker='o', label='Class 1', alpha=0.7, edgecolor='k')\n",
    "        plt.scatter(X[y == -1][:, 0], X[y == -1][:, 1],\n",
    "                    c='red', marker='s', label='Class -1', alpha=0.7, edgecolor='k')\n",
    "\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "        if abs(w2) < 1e-5:\n",
    "            if abs(w1) < 1e-5:\n",
    "                 print(\"Warning: Both w1 and w2 are close to zero. Cannot plot boundary.\")\n",
    "            else:\n",
    "                boundary_x = -w0 / w1\n",
    "                if x_min <= boundary_x <= x_max:\n",
    "                    plt.axvline(x=boundary_x, color='k', linestyle='-', label='Decision Boundary')\n",
    "        else:\n",
    "            x_boundary = np.array([x_min, x_max])\n",
    "            y_boundary = (-w0 - w1 * x_boundary) / w2\n",
    "            plt.plot(x_boundary, y_boundary, 'k-', label='Decision Boundary')\n",
    "\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.title('Perceptron Decision Boundary')\n",
    "        plt.xlim(x_min, x_max)\n",
    "        plt.ylim(y_min, y_max)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38cf279-13af-4402-94c4-2c418d3d97a5",
   "metadata": {},
   "source": [
    "* Split data to 70-30 train-test sets **1 pt**.\n",
    "* Train your perceptron.\n",
    "* Show the accuracy of your pereptron **2 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7986537a-e054-4286-91a4-9ba639e3c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_df = df.drop(['diabetes'], axis=1)\n",
    "y_series = df['diabetes']\n",
    "\n",
    "X_np = X_df.values\n",
    "y_np = y_series.values\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_np, y_np, test_size=0.30, random_state=42 # Removed stratify=y as y is now float, stratification is tricky unless targets are integers/classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22521abe-9552-41ec-8512-6995a7245ed7",
   "metadata": {},
   "source": [
    "* Use test set to evaulate the accuracy of your perceptron. What is your accuracy? (**2 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6dd4c5-7bc1-4e9b-83e4-0417543b52d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Perceptron on the test set is: 0.9151\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "p = Perceptron()\n",
    "p.fit(X_train, y_train)\n",
    "y_pred = [p.predict(xi) for xi in X_test]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nThe accuracy of the Perceptron on the test set is: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59cd13-1358-48ad-a11c-2371277e0b55",
   "metadata": {},
   "source": [
    "* There may be some ways to increase the accruacy, such as increasing the number of train iterations or adjust learning rate. Give a try to train a perceptron you can best get. Record the values of parameters and the optimal accuracy. (**3 pt**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3498a824-d111-451e-9119-6f85964bca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Perceptron on the test set is: 0.9151\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "p = Perceptron(iterations=50, learning_rate=.005)\n",
    "p.fit(X_train, y_train)\n",
    "y_pred = [p.predict(xi) for xi in X_test]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nThe accuracy of the Perceptron on the test set is: {accuracy:.4f}\")\n",
    "\n",
    "#no matter what i do the accuracy is always .9151"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41900123-9fa6-4dbb-81de-0b90edc3d9e5",
   "metadata": {},
   "source": [
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Next we shall test perceptron's capability of multiple-label classification.\n",
    "\n",
    "* Dowdload the dataset from `https://raw.githubusercontent.com/huichiayu/cmse202-s25-supllemental_data/refs/heads/main/HW04/Telecust1.csv`.\n",
    "* This is a customer category dataset (Kraggle/Customer Classification). Each cusmtoer has several feature variables.\n",
    "* There are five categories of customers, which are non-numerics. Thus, let's convert those string labels to numerics.\n",
    "* Successful data load-up gets **2 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f57127a-9d83-4408-a18d-8adfb800eb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region     int64\n",
       "tenure     int64\n",
       "age        int64\n",
       "income     int64\n",
       "marital    int64\n",
       "address    int64\n",
       "ed         int64\n",
       "employ     int64\n",
       "retire     int64\n",
       "gender     int64\n",
       "reside     int64\n",
       "custcat    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Telecust1.csv')\n",
    "df.custcat = df.custcat.map({'A': 0,'B': 1,'C': 2,'D': 3})\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcab03b-57fb-4268-81dc-e72281bfceb1",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.4 Multi-label perceptron classification\n",
    "\n",
    "* As we know, perceptron is a binary classifier. For multiple-label classification, we can use One-vs-Rest (OvR) Strategy.\n",
    "* In this case, let's train five individual perceptrons. \n",
    "* For each classifier, it treats the current class as \"positive\" and all others as \"negative.\"\n",
    "* When classifying a new sample, each classifier gives a \"score,\" and the class with the highest score is chosen.\n",
    "\n",
    "Copy your perceptron to the code cell below. We need to add a score method, which outputs dot of weights and features, as opposed to the previous binary predict method. The score method should output a signed floating score value, not `+1` or `-1`. This can be done by removing the binary segmenting, i.e., directly outputing the dot value.\n",
    "\n",
    "* Functioning score() method gets **2 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7996b89-84fb-4272-9c30-c5293a97455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random # Needed for shuffling in Perceptron\n",
    "\n",
    "# --- Paste the refined Perceptron Class Code Here ---\n",
    "# (Make sure the class definition from the previous answer is included)\n",
    "class Perceptron():\n",
    "    \"\"\"\n",
    "    A simple implementation of the Perceptron algorithm for binary classification.\n",
    "\n",
    "    Attributes:\n",
    "        iterations (int): The number of passes over the training dataset.\n",
    "        learning_rate (float): The step size for weight updates.\n",
    "        weights (np.ndarray): The learned weights (including the bias term at index 0).\n",
    "        data (np.ndarray): The training data stored internally (used only during fit).\n",
    "        errors_ (list): Stores the number of misclassifications per epoch during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, iterations=100, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Initializes the Perceptron classifier hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            iterations (int): Maximum number of training iterations (epochs).\n",
    "            learning_rate (float): The learning rate (eta).\n",
    "        \"\"\"\n",
    "        # Initialize weights later in fit() once data dimension is known\n",
    "        self.weights = None\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.errors_ = [] # To store number of misclassifications per epoch\n",
    "\n",
    "    def _initialize_weights(self, num_features):\n",
    "         \"\"\"Initializes weights to zeros based on number of features.\"\"\"\n",
    "         self.weights = np.zeros(num_features + 1) # +1 for bias\n",
    "\n",
    "    def predict(self, feature_set):\n",
    "        if self.weights is None:\n",
    "            raise RuntimeError(\"Perceptron must be trained before prediction.\")\n",
    "\n",
    "        features = np.asarray(feature_set)\n",
    "        # Calculate activation: w0 + w1*x1 + w2*x2 + ...\n",
    "        activation = self.weights[0] + np.dot(features, self.weights[1:])\n",
    "        # Return +1 if activation >= 0, else -1 (step function)\n",
    "        return 1 if activation >= 0 else -1\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Trains the Perceptron model on the provided training data.\n",
    "\n",
    "        Args:\n",
    "            X_train (np.ndarray): Training features (samples x features).\n",
    "            y_train (np.ndarray): Training labels (samples x 1).\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X_train.shape\n",
    "\n",
    "        # Initialize weights based on training data dimensions\n",
    "        self._initialize_weights(n_features)\n",
    "\n",
    "        # Verify labels are -1 and 1\n",
    "        unique_labels = np.unique(y_train)\n",
    "        if not (len(unique_labels) == 2 and np.all(np.isin(unique_labels, [-1, 1]))):\n",
    "             raise ValueError(\"Training labels must be exactly -1 and 1.\")\n",
    "\n",
    "        # Combine features and labels for easier iteration during training\n",
    "        training_data = np.hstack((X_train, y_train.reshape(-1, 1)))\n",
    "\n",
    "        self.errors_ = [] # Reset errors history\n",
    "        for epoch in range(self.iterations):\n",
    "            errors_in_epoch = 0\n",
    "            # Shuffle data each epoch to avoid cycles\n",
    "            np.random.shuffle(training_data)\n",
    "\n",
    "            for sample in training_data:\n",
    "                features = sample[:-1]\n",
    "                target = sample[-1]\n",
    "                prediction = self.predict(features) # Use internal predict\n",
    "\n",
    "                # If prediction is wrong, update weights\n",
    "                if prediction != target:\n",
    "                    # Standard Perceptron update rule: w = w + learning_rate * target * x\n",
    "                    update = self.learning_rate * target\n",
    "                    self.weights[1:] += update * features # Update feature weights (w1, w2, ...)\n",
    "                    self.weights[0] += update             # Update bias weight (w0)\n",
    "                    errors_in_epoch += 1\n",
    "\n",
    "            self.errors_.append(errors_in_epoch)\n",
    "            # Optional: Stopping condition\n",
    "            # if errors_in_epoch == 0:\n",
    "            #     print(f\"Converged after {epoch+1} epochs.\")\n",
    "            #     break\n",
    "\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"Calculates accuracy on the test set.\"\"\"\n",
    "        y_pred = np.array([self.predict(xi) for xi in X_test])\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    def plot_decision_boundary(self, X, y):\n",
    "        \"\"\"\n",
    "        Plots the data points and the decision boundary learned by the Perceptron.\n",
    "        Assumes the data has exactly 2 features.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Features (samples x features).\n",
    "            y (np.ndarray): Labels (samples x 1).\n",
    "        \"\"\"\n",
    "        if self.weights is None:\n",
    "             raise RuntimeError(\"Perceptron must be trained before plotting.\")\n",
    "        if X.shape[1] != 2:\n",
    "            print(\"Warning: Plotting decision boundary only implemented for 2 features.\")\n",
    "            return\n",
    "\n",
    "        w0, w1, w2 = self.weights  # Bias, weight_feature1, weight_feature2\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1],\n",
    "                    c='blue', marker='o', label='Class 1', alpha=0.7, edgecolor='k')\n",
    "        plt.scatter(X[y == -1][:, 0], X[y == -1][:, 1],\n",
    "                    c='red', marker='s', label='Class -1', alpha=0.7, edgecolor='k')\n",
    "\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "        if abs(w2) < 1e-5:\n",
    "            if abs(w1) < 1e-5:\n",
    "                 print(\"Warning: Both w1 and w2 are close to zero. Cannot plot boundary.\")\n",
    "            else:\n",
    "                boundary_x = -w0 / w1\n",
    "                if x_min <= boundary_x <= x_max:\n",
    "                    plt.axvline(x=boundary_x, color='k', linestyle='-', label='Decision Boundary')\n",
    "        else:\n",
    "            x_boundary = np.array([x_min, x_max])\n",
    "            y_boundary = (-w0 - w1 * x_boundary) / w2\n",
    "            plt.plot(x_boundary, y_boundary, 'k-', label='Decision Boundary')\n",
    "\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.title('Perceptron Decision Boundary')\n",
    "        plt.xlim(x_min, x_max)\n",
    "        plt.ylim(y_min, y_max)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "    def score(self, feature_set):\n",
    "        \"\"\"\n",
    "        Calculates the raw activation score for a single feature set.\n",
    "        This is the value before applying the sign function for prediction.\n",
    "\n",
    "        Args:\n",
    "            feature_set (np.ndarray or list): A single sample's features.\n",
    "\n",
    "        Returns:\n",
    "            float: The raw activation score (w0 + w . x).\n",
    "        \"\"\"\n",
    "        if self.weights is None:\n",
    "            raise RuntimeError(\"Perceptron must be trained before scoring.\")\n",
    "\n",
    "        # Ensure feature_set is a numpy array\n",
    "        features = np.asarray(feature_set)\n",
    "\n",
    "        # Calculate activation: w0 + w1*x1 + w2*x2 + ...\n",
    "        # Use self.weights[1:] for feature weights, features for input values\n",
    "        activation = self.weights[0] + np.dot(features, self.weights[1:])\n",
    "\n",
    "        # Return the raw score directly\n",
    "        return activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e1e42-e58d-49c5-a7ce-bdbb9f8e3d50",
   "metadata": {},
   "source": [
    "* Now let's do a train-test split of the data with a test_size = 0.3.\n",
    "* Since we are training 5 perceptrons, we should have have 5 class label sets. For instance, in the label set for category A, the label value will be `+1` if it's type A and otherwise `-1`.\n",
    "* Setting label sets gets **4 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e59a1422-8984-49b8-889e-e34c6172e8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created OvR labels for class '0'.\n",
      "  Created OvR labels for class '1'.\n",
      "  Created OvR labels for class '2'.\n",
      "  Created OvR labels for class '3'.\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['custcat'], axis=1)\n",
    "y = df['custcat']\n",
    "X_np = X.values\n",
    "y_np = y.values\n",
    "X_train, X_test, y_train_orig, y_test_orig = train_test_split(\n",
    "    X_np,\n",
    "    y_np,             # Use original numerical labels (0-4)\n",
    "    test_size=0.30,\n",
    "    random_state=42,  # For reproducibility\n",
    "    stratify=y_np     # Stratify should work with integer classes 0-4\n",
    ")\n",
    "\n",
    "y_train_ovr = {}\n",
    "y_test_ovr = {}\n",
    "unique_classes = np.unique(y_np)\n",
    "\n",
    "for target_class in sorted(unique_classes): # Sort classes for consistent order\n",
    "    # Create training labels for the current class\n",
    "    y_train_ovr[target_class] = np.where(y_train_orig == target_class, 1, -1)\n",
    "\n",
    "    # Create testing labels for the current class\n",
    "    y_test_ovr[target_class] = np.where(y_test_orig == target_class, 1, -1)\n",
    "\n",
    "    print(f\"  Created OvR labels for class '{target_class}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245187a-3ed6-4cc4-a844-7fd0493707c9",
   "metadata": {},
   "source": [
    "* Use training set and the 5 training label sets to train your 5 perceptrons. Report the accuracy of those five training.\n",
    "* Efficiently train the five perceptrons using nest loop gets **5 pt**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be107995-7f86-48d8-b24a-d3f3ed8b9e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 4 One-vs-Rest Perceptrons...\n",
      "\n",
      "--- Training Perceptron for class: 0 (vs Rest) ---\n",
      "Fitting model for class 0...\n",
      "Model for class 0 trained.\n",
      "Evaluating training accuracy for class 0 model...\n",
      "--> Training Accuracy for class 0 Perceptron: 0.6400 (64.00%)\n",
      "\n",
      "--- Training Perceptron for class: 1 (vs Rest) ---\n",
      "Fitting model for class 1...\n",
      "Model for class 1 trained.\n",
      "Evaluating training accuracy for class 1 model...\n",
      "--> Training Accuracy for class 1 Perceptron: 0.7429 (74.29%)\n",
      "\n",
      "--- Training Perceptron for class: 2 (vs Rest) ---\n",
      "Fitting model for class 2...\n",
      "Model for class 2 trained.\n",
      "Evaluating training accuracy for class 2 model...\n",
      "--> Training Accuracy for class 2 Perceptron: 0.7186 (71.86%)\n",
      "\n",
      "--- Training Perceptron for class: 3 (vs Rest) ---\n",
      "Fitting model for class 3...\n",
      "Model for class 3 trained.\n",
      "Evaluating training accuracy for class 3 model...\n",
      "--> Training Accuracy for class 3 Perceptron: 0.7700 (77.00%)\n",
      "\n",
      "--- Training Complete ---\n",
      "Total training time: 1.54 seconds\n",
      "\n",
      "Summary of Training Accuracies:\n",
      "  Class 0 vs Rest: 0.6400 (64.00%)\n",
      "  Class 1 vs Rest: 0.7429 (74.29%)\n",
      "  Class 2 vs Rest: 0.7186 (71.86%)\n",
      "  Class 3 vs Rest: 0.7700 (77.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time # Optional: to time the training\n",
    "\n",
    "\n",
    "# Dictionary to store the trained perceptron models\n",
    "trained_perceptrons = {}\n",
    "# Dictionary to store the training accuracy for each model\n",
    "training_accuracies = {}\n",
    "\n",
    "print(f\"Starting training for {len(unique_classes)} One-vs-Rest Perceptrons...\")\n",
    "start_time = time.time() # Optional timer\n",
    "\n",
    "# Loop through each class to train a specific Perceptron\n",
    "for target_class in unique_classes:\n",
    "    print(f\"\\n--- Training Perceptron for class: {target_class} (vs Rest) ---\")\n",
    "\n",
    "    # 1. Instantiate a new Perceptron for this class\n",
    "    #    (You can adjust hyperparameters if needed)\n",
    "    ppn = Perceptron(iterations=100, learning_rate=0.01)\n",
    "\n",
    "    # 2. Get the correct +1/-1 training labels for this class\n",
    "    y_train_current = y_train_ovr[target_class]\n",
    "\n",
    "    # 3. Train the Perceptron\n",
    "    print(f\"Fitting model for class {target_class}...\")\n",
    "    ppn.fit(X_train, y_train_current)\n",
    "\n",
    "    # 4. Store the trained model\n",
    "    trained_perceptrons[target_class] = ppn\n",
    "    print(f\"Model for class {target_class} trained.\")\n",
    "\n",
    "    # 5. Evaluate accuracy on the TRAINING data\n",
    "    print(f\"Evaluating training accuracy for class {target_class} model...\")\n",
    "    y_train_pred = [ppn.predict(xi) for xi in X_train]\n",
    "    accuracy = accuracy_score(y_train_current, y_train_pred)\n",
    "    training_accuracies[target_class] = accuracy\n",
    "\n",
    "    print(f\"--> Training Accuracy for class {target_class} Perceptron: {accuracy:.4f} ({accuracy * 100:.2f}%)\")\n",
    "\n",
    "# End of loop\n",
    "end_time = time.time() # Optional timer\n",
    "print(f\"\\n--- Training Complete ---\")\n",
    "print(f\"Total training time: {end_time - start_time:.2f} seconds\") # Optional timer\n",
    "\n",
    "print(\"\\nSummary of Training Accuracies:\")\n",
    "for target_class, acc in training_accuracies.items():\n",
    "    print(f\"  Class {target_class} vs Rest: {acc:.4f} ({acc * 100:.2f}%)\")\n",
    "\n",
    "# You now have a dictionary 'trained_perceptrons' containing one trained model for each class.\n",
    "# You also have 'training_accuracies' storing the accuracy of each model on its specific OvR training task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e550cc5-fbc2-42a2-8713-881783f2c7f9",
   "metadata": {},
   "source": [
    "* Use the test vector to examine the accuracy.\n",
    "* For each feature set, there should be 5 output scores, each from a perceptron. The predicted label should be the label that corresponds to the highest score.\n",
    "* Report your accuracy. (**3 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e549131-9459-437b-b627-bc99e0fa93cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores from each Perceptron for all test samples...\n",
      "\n",
      "Example predicted classes (first 20): [0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "Example true classes      (first 20): [2 1 2 2 2 3 0 1 2 2 1 2 0 0 1 3 3 0 1 3]\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Final Accuracy of the OvR Perceptron model on the Test Set: 0.3500 (35.00%)\n"
     ]
    }
   ],
   "source": [
    "num_test_samples = X_test.shape[0]\n",
    "num_classes = len(unique_classes)\n",
    "unique_classes_array = np.array(unique_classes) # Use numpy array for potential indexing\n",
    "\n",
    "# 1. Create a matrix to store scores from each classifier for each test sample\n",
    "#    Rows = samples, Columns = scores from classifier for class 0, 1, 2, 3, 4\n",
    "all_scores = np.zeros((num_test_samples, num_classes))\n",
    "\n",
    "# 2. Populate the score matrix\n",
    "print(\"Calculating scores from each Perceptron for all test samples...\")\n",
    "for idx, target_class in enumerate(unique_classes_array):\n",
    "    # Get the perceptron trained for this class (e.g., class 0)\n",
    "    ppn = trained_perceptrons[target_class]\n",
    "\n",
    "    # Calculate scores for ALL test samples using this perceptron's score method\n",
    "    # This loop runs num_classes times (e.g., 5 times)\n",
    "    scores_for_class = np.array([ppn.score(xi) for xi in X_test])\n",
    "\n",
    "    # Store these scores in the column corresponding to this class's index\n",
    "    all_scores[:, idx] = scores_for_class\n",
    "    # print(f\"  Scores calculated using model for class {target_class}.\") # Optional print\n",
    "\n",
    "# 3. Find the class with the highest score for each sample\n",
    "#    np.argmax returns the *index* of the maximum value along axis=1 (each row)\n",
    "pred_indices = np.argmax(all_scores, axis=1)\n",
    "# Example: if for row 0, scores are [-2.1, 0.5, 3.1, -1.0, 2.5], argmax returns 2\n",
    "\n",
    "# 4. Map the indices back to the original class labels\n",
    "#    Use the sorted unique_classes_array for mapping index -> class label\n",
    "y_pred_final = unique_classes_array[pred_indices]\n",
    "# Example: if pred_indices[0] is 2, y_pred_final[0] becomes unique_classes_array[2] (which is likely 2)\n",
    "\n",
    "print(f\"\\nExample predicted classes (first 20): {y_pred_final[:20]}\")\n",
    "print(f\"Example true classes      (first 20): {y_test_orig[:20]}\")\n",
    "\n",
    "# 5. Calculate the overall accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test_orig, y_pred_final)\n",
    "\n",
    "print(\"\\n--- Evaluation Complete ---\")\n",
    "print(f\"Final Accuracy of the OvR Perceptron model on the Test Set: {test_accuracy:.4f} ({test_accuracy * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31084b-0308-4fd0-b912-bf42f13ee674",
   "metadata": {},
   "source": [
    "How good is your multiple-label perceptron classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c598a593-aac1-48b7-b634-f6c046f256f3",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> worse than random(25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08b1bce-e2ce-4bd4-ae8e-9aca6d76a163",
   "metadata": {},
   "source": [
    "\n",
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "---\n",
    "## Part 3 SVM classifiers (19 points)\n",
    "\n",
    "### 3.1 SVM \n",
    "\n",
    "Let's re-use the customer category data. There are five caterogies with multiple feature variables.\n",
    "\n",
    "* Use sklearn library to build a SVM classifier. Since we do not know what the best parametes are, perform a GridSearch for best parameters.\n",
    "* NOTE: Because the dataset contains a large number of points, it's expected to have a long computer running time for GridSearch. Thus, let's use only the first 200 data points for GridSearch. You can start the grid search parameter like the image below. However, **NOTE** that if the kernal used cannot find a hyperplane to classify data points, the GridSearch function will stall. You need to manually remove that kernal from the parameter set and re-run GridSearch.\n",
    "  \n",
    "<img src=\"https://i.ibb.co/JWrp6c4q/Grid-Search-Param.png\" width=\"650\">\n",
    "\n",
    "\n",
    "* As in the previous section, make a 70-30 train-test split and train your SVM classifier.\n",
    "* Complete GridSearch to extract best parameters gets **5 pt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb83c8b3-cc1b-4fa6-a2f7-f627339586d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simplified SVM GridSearch setup...\n",
      "Using subset of data with shape: (200, 12)\n",
      "Split into 140 training and 60 test samples.\n",
      "\n",
      "Using simplified parameter grid:\n",
      "{'C': [0.1, 1.0, 10.0], 'gamma': [0.001, 0.1, 1], 'kernel': ['linear', 'rbf']}\n",
      "\n",
      "Setting up simplified GridSearchCV (cv=3, n_jobs=1)...\n",
      "Running simplified GridSearchCV...\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Simplified GridSearchCV finished.\n",
      "\n",
      "--- Simplified GridSearchCV Results ---\n",
      "Best parameters found:\n",
      "{'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "\n",
      "Best cross-validation accuracy score:\n",
      "0.4002\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df = pd.read_csv('Telecust1.csv')\n",
    "df['custcat'] = df['custcat'].map({'A': 0,'B': 1,'C': 2,'D': 3,'E': 4})\n",
    "\n",
    "\n",
    "df_subset = df.head(200)\n",
    "\n",
    "X_subset = df_subset.drop(['custcat'], axis=1)\n",
    "y_subset = df_subset['custcat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_subset,\n",
    "    y_subset,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y_subset\n",
    ")\n",
    "\n",
    "param_grid_simple = {\n",
    "    'C': [0.1, 1.0, 10.0],        # Reduced C values (3 options)\n",
    "    'gamma': [0.001, 0.1, 1],   # Reduced gamma values (3 options)\n",
    "    'kernel': ['linear', 'rbf'] # Reduced kernels (2 options - removed sigmoid)\n",
    "    # Total combinations = 3 * 3 * 2 = 18 (much less than 60)\n",
    "}\n",
    "\n",
    "\n",
    "svc_estimator = SVC(class_weight='balanced')\n",
    "\n",
    "\n",
    "clf_simple = GridSearchCV(\n",
    "    estimator=svc_estimator,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=3,           # Reduced CV folds\n",
    "    n_jobs=1,       # Run sequentially (no parallelization)\n",
    "    verbose=1       # Set verbose=1 to see some progress\n",
    ")\n",
    "\n",
    "try:\n",
    "    clf_simple.fit(X_train, y_train)\n",
    "    print(\"Simplified GridSearchCV finished.\")\n",
    "\n",
    "    # 9. Extract and print the best parameters and score\n",
    "    print(\"\\n--- Simplified GridSearchCV Results ---\")\n",
    "    print(\"Best parameters found:\")\n",
    "    print(clf_simple.best_params_)\n",
    "    print(\"\\nBest cross-validation accuracy score:\")\n",
    "    print(f\"{clf_simple.best_score_:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during GridSearchCV: {e}\")\n",
    "    print(\"The server might still be running out of resources.\")\n",
    "    print(\"Consider reducing the parameter grid or cv folds further,\")\n",
    "    print(\"or contacting your JupyterHub administrator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af730354-6eee-40f2-9a19-a20c8be0f3db",
   "metadata": {},
   "source": [
    "* Examine the accuracy of this SVC and report the accuracy. Draw a confusion matrix. **2 pt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527b7f0b-97b1-474f-b0b0-09574d54a6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the best SVM model found by GridSearchCV on the test set...\n",
      "\n",
      "Best SVM Estimator retrieved:\n",
      "SVC(C=0.1, class_weight='balanced', gamma=0.001, kernel='linear')\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "--- Accuracy ---\n",
      "Accuracy of the best SVM on the test set: 0.3333 (33.33%)\n",
      "\n",
      "--- Confusion Matrix ---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAJNCAYAAADJZIQ0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAV49JREFUeJzt3Xd4FOXax/HfJiSbuqGZQCCEJr0XaSooRWnC8YAgioCABSyIIiLS9EAAPQiiVGmiNKWICBxRigXQ0ESKYAEBIXQSCC1l3j8w+7IkgSQkO5vJ9+M11zk7OzvPvTtJ9uZ+ytgMwzAEAACQy3mZHQAAAEB2IKkBAACWQFIDAAAsgaQGAABYAkkNAACwBJIaAABgCSQ1AADAEkhqAACAJZDUAAAASyCpAQAAlkBSAwAActS3336rtm3bKjw8XDabTcuWLXM+l5CQoIEDB6pq1aoKDAxUeHi4nnjiCR09ejTT7ZDUAACAHBUfH6/q1avr/fffT/XcxYsXtW3bNg0ZMkTbtm3TkiVLtH//fj300EOZbsfGDS0BAIC72Gw2LV26VO3bt0/3mOjoaN11113666+/VKJEiQyfO182xAcAAEx2+fJlXb161W3tGYYhm83mss9ut8tut9/2uWNjY2Wz2ZQ/f/5MvY6kBgCAXO7y5cvyDy4kJV50W5tBQUG6cOGCy75hw4Zp+PDht3Xey5cv67XXXlOXLl3kcDgy9VqSGgAAcrmrV69KiRdlr9RN8vbN+QaTrurCnjk6fPiwS+Jxu1WahIQEde7cWcnJyZo0aVKmX09SAwCAVeTzk80NSY1huzbPyOFwZLqakp6EhAQ98sgjOnDggNauXZul85LUAAAAU6UkNL/99pvWrVunQoUKZek8JDUAAFiFTdINg3dzrJ1MuHDhgn7//Xfn4wMHDmjHjh0qWLCgwsPD1aFDB23btk0rVqxQUlKSYmJiJEkFCxaUr2/GK09M6QYAIJeLi4tTSEiI7NWfls379mcf3YqRdEVXfp6q2NjYDHUTrV+/Xvfdd1+q/d26ddPw4cNVqlSpNF+3bt06NWnSJMNxUakBAMAqbF7XNne0kwlNmjTRzWoo2VVfYUVhAABgCVRqAACwCpvNTWNq3NBGFlCpAQAAlkClBgAAq/DQMTXu4plRAQAAZBJJDQAAsAS6nwAAsAoGCgMAAOR+VGoAALAMNw0U9tCaiGdGBQAAkElUagAAsArG1AAAAOR+VGoAALAKFt8DAADI/ajUAABgFYypAQAAyP2o1AAAYBWMqQEAAMj9SGoAAIAl0P0EAIBVMFAYAAAg96NSAwCAVTBQGAAAIPejUgMAgFXYbG6q1DCmBgAAIMdQqQEAwCq8bNc2d7TjgajUAAAAS6BSAwCAVTD7CQAAIPejUgMAgFWwojAAAEDuR1IDAAAsge4nAACsgoHCAAAAuR+VGgAArIKBwgAAALkflRoAAKyCMTUAAAC5H0mNG+zcuVM9evRQqVKl5Ofnp6CgINWqVUtjx47VmTNncrTt7du3q3HjxgoJCZHNZtP48eOzvQ2bzabhw4dn+3lvZfbs2bLZbLLZbFq/fn2q5w3DUNmyZWWz2dSkSZMstTFp0iTNnj07U69Zv359ujFl1cKFC1W5cmX5+/vLZrNpx44d2XbuG6XEf/1WoEAB1atXT3PmzMmxdiVp1KhRWrZsWYaPP336tAYNGqRKlSopMDBQISEhqlChgrp27aqdO3dKkv71r3/J399f586dS/c8jz32mHx8fHT8+HFJcr7v7t27p3n8m2++6Tzm4MGDGY43Jxw8eDDV9Upvy45Yjx49quHDh2fqZ3Dv3r3q2rWrSpcuLT8/PxUuXFi1atXSc889p7i4uEzHsHHjRg0fPvym1zTPShlT447NA9H9lMOmT5+uPn36qHz58howYIAqVaqkhIQEbdmyRVOmTNGmTZu0dOnSHGv/ySefVHx8vBYsWKACBQqoZMmS2d7Gpk2bVLx48Ww/b0YFBwdrxowZqRKXDRs26I8//lBwcHCWzz1p0iQVLlw43S+3tNSqVUubNm1SpUqVstzu9U6ePKmuXbvqwQcf1KRJk2S321WuXLlsOffNjBo1Svfdd58k6dSpU/roo4/UvXt3xcXF6fnnn8+xNjt06KD27dvf8tgLFy6ofv36unDhggYMGKDq1avr0qVL2r9/v5YsWaIdO3aoWrVq6tmzp5YtW6Z58+apT58+qc4TGxurpUuXqk2bNgoLC3PuDw4O1qeffqqJEye6/AwZhqHZs2fL4XBk6Qs5uxUtWlSbNm1y2denTx/Fxsbqk08+SXXs7Tp69KhGjBihkiVLqkaNGrc8fvv27WrUqJEqVqyooUOHqmTJkjp16pR+/vlnLViwQK+88oocDkemYti4caNGjBih7t27K3/+/Fl7I7AkkpoctGnTJj377LNq3ry5li1bJrvd7nyuefPmevnll7V69eocjWHXrl3q3bu3WrZsmWNt1K9fP8fOnRGdOnXSJ598og8++MDlj+OMGTPUoEEDt33xJCQkyGazyeFwZOtnsn//fiUkJOjxxx9X48aNs+WcFy9eVEBAwE2PufPOO13eR6tWrRQdHa358+fnWFKTGZ9++ql+//13rV271pl8pejfv7+Sk5MlSS1btlR4eLhmzpyZZlIzf/58Xbp0ST179nTZ365dOy1evFgLFixQ7969nfvXrl2rAwcOqHfv3po+fXoOvLPMsdvtqX7eHA6Hrl69avrvpiSNHz9eXl5eWr9+vUty2KFDB7311lsyDMPE6CyIMTXIKaNGjZLNZtO0adNcEpoUvr6+euihh5yPk5OTNXbsWFWoUEF2u12hoaF64okndOTIEZfXNWnSRFWqVFF0dLTuueceBQQEqHTp0ho9erTzD3lK10xiYqImT57sLD9L0vDhw53//3opr7m+RL127Vo1adJEhQoVkr+/v0qUKKF///vfunjxovOYtLqfdu3apXbt2qlAgQLy8/NTjRo1UnVdpHRzzJ8/X4MHD1Z4eLgcDoeaNWumffv2ZexDlvToo49KuvbllCI2NlaLFy/Wk08+meZrRowYoXr16qlgwYJyOByqVauWZsyY4fIHtmTJktq9e7c2bNjg/PxSKl0psc+dO1cvv/yyihUrJrvdrt9//z1V99OpU6cUERGhhg0bKiEhwXn+PXv2KDAwUF27dk33vXXv3l133323pGvJ241dacuXL1eDBg0UEBCg4OBgNW/ePNW/2lOu97Zt29ShQwcVKFBAZcqUufUHewMvLy8FBQXJx8fHZb9hGJo0aZJq1Kghf39/FShQQB06dNCff/7pctz27dvVpk0bhYaGym63Kzw8XK1bt3b+fNtsNsXHx2vOnDnOz/tm3YanT5+WlH71wcvr2p83b29vdevWTVu3btUvv/yS6rhZs2apaNGiqRL/kJAQ/etf/9LMmTNd9s+cOVONGjXKVLXs+++/V9OmTRUcHKyAgAA1bNhQX375pcsxKb9/69at07PPPqvChQurUKFCevjhh3X06NEMt5WeuLg4vfLKKypVqpR8fX1VrFgx9evXT/Hx8S7Hffrpp6pXr55CQkKcf1tSfo/Wr1+vunXrSpJ69OjhvE43634+ffq0HA6HgoKC0nz+xr9FX3/9tZo2bSqHw6GAgAA1atRI33zzjfP54cOHa8CAAZKkUqVK3bQLGnkPSU0OSUpK0tq1a1W7dm1FRERk6DXPPvusBg4cqObNm2v58uV66623tHr1ajVs2FCnTp1yOTYmJkaPPfaYHn/8cS1fvlwtW7bUoEGD9PHHH0uSWrdu7fxy69ChgzZt2pTqy+5WDh48qNatW8vX11czZ87U6tWrNXr0aAUGBurq1avpvm7fvn1q2LChdu/erffee09LlixRpUqV1L17d40dOzbV8a+//rr++usvffjhh5o2bZp+++03tW3bVklJSRmK0+FwqEOHDi5fPvPnz5eXl5c6deqU7nt7+umntWjRIi1ZskQPP/ywnn/+eb311lvOY5YuXarSpUurZs2azs/vxq7CQYMG6dChQ5oyZYq++OILhYaGpmqrcOHCWrBggaKjozVw4EBJ1yolHTt2VIkSJTRlypR039uQIUP0wQcfSLqWJG/atEmTJk2SJM2bN0/t2rWTw+HQ/PnzNWPGDJ09e1ZNmjTR999/n+pcDz/8sMqWLatPP/30pm2mSE5OVmJiohITE3X8+HGNHj1au3bt0uOPP+5y3NNPP61+/fqpWbNmWrZsmSZNmqTdu3erYcOGzjEq8fHxat68uY4fP64PPvhAa9as0fjx41WiRAmdP39e0rXKpr+/v1q1auX8vFPea1oaNGggSXriiSe0bNkyZ5KTlieffFI2my1VgrJnzx799NNP6tatm7y9vVO9rmfPntq8ebP27t0rSTp37pyWLFmSqqpzMxs2bND999+v2NhYzZgxQ/Pnz1dwcLDatm2rhQsXpjq+V69e8vHx0bx58zR27FitX78+1WeeWRcvXlTjxo01Z84cvfDCC1q1apUGDhyo2bNn66GHHnIm85s2bVKnTp1UunRpLViwQF9++aWGDh2qxMRESde6VmfNmiVJeuONN5zXqVevXum23aBBAx07dkyPPfaYNmzYoEuXLqV77Mcff6wWLVrI4XBozpw5WrRokQoWLKgHHnjAmdj06tXLWSlcsmSJM4ZatWrd1mdkGXl8TI0M5IiYmBhDktG5c+cMHb93715DktGnTx+X/T/++KMhyXj99ded+xo3bmxIMn788UeXYytVqmQ88MADLvskGX379nXZN2zYMCOtSz9r1ixDknHgwAHDMAzjs88+MyQZO3bsuGnskoxhw4Y5H3fu3Nmw2+3GoUOHXI5r2bKlERAQYJw7d84wDMNYt26dIclo1aqVy3GLFi0yJBmbNm26absp8UZHRzvPtWvXLsMwDKNu3bpG9+7dDcMwjMqVKxuNGzdO9zxJSUlGQkKC8eabbxqFChUykpOTnc+l99qU9u699950n1u3bp3L/jFjxhiSjKVLlxrdunUz/P39jZ07d970PV5/vk8//dQl5vDwcKNq1apGUlKSc//58+eN0NBQo2HDhs59Kdd76NCht2zr+vZu3Ly8vIzBgwe7HLtp0yZDkvHf//7XZf/hw4cNf39/49VXXzUMwzC2bNliSDKWLVt207YDAwONbt26ZShOwzCMN9980/D19XXGWKpUKeOZZ54xfv7551THNm7c2ChcuLBx9epV576XX37ZkGTs37/f5diU35vk5GSjVKlSxiuvvGIYhmF88MEHRlBQkHH+/Hnj7bffdvl9SU/9+vWN0NBQ4/z58859iYmJRpUqVYzixYs7f95Sfp5v/BswduxYQ5Jx7NixDH8ujRs3NipXrux8HBUVZXh5eRnR0dEux6X8jq9cudIwDMN45513DEnO39G0REdHG5KMWbNmZSiWy5cvG+3bt3deI29vb6NmzZrG4MGDjRMnTjiPi4+PNwoWLGi0bdvW5fVJSUlG9erVjbvuusu5L6OffV4SGxtrSDLszUYZfg+Oy/HN3myUIcmIjY01+627oFLjIdatWydJqQak3nXXXapYsaJL+VWSihQporvuustlX7Vq1fTXX39lW0w1atSQr6+vnnrqKc2ZMydVd0J61q5dq6ZNm6aqUHXv3l0XL15MVTG6vgtOuvY+JGXqvTRu3FhlypTRzJkz9csvvyg6OjrdrqeUGJs1a6aQkBB5e3vLx8dHQ4cO1enTp3XixIkMt/vvf/87w8cOGDBArVu31qOPPqo5c+Zo4sSJqlq1aoZff719+/bp6NGj6tq1q7ObRZKCgoL073//W5s3b3bpIsxsrJI0ZswYRUdHKzo6WmvWrNGrr76q0aNHO0v/krRixQrZbDY9/vjjzqpOYmKiihQpourVqzu7BMqWLasCBQpo4MCBmjJlivbs2ZOl932jIUOG6NChQ5o5c6aefvppBQUFacqUKapdu7ZLd6R0repy6tQpLV++XJKUmJiojz/+WPfcc4/uvPPONM+fMgNq7ty5SkxM1IwZM/TII4+k25Vyo/j4eP3444/q0KGDy2u8vb3VtWtXHTlyJFVXa3b8PtxoxYoVqlKlimrUqOFynR544AGXrpuUrqVHHnlEixYt0t9//53lNlPY7XYtXbpUe/bs0bvvvqvOnTvr5MmTGjlypCpWrOh8/xs3btSZM2fUrVs3lxiTk5P14IMPKjo6OlVXGXAjkpocUrhwYQUEBOjAgQMZOv5m4wPCw8NTldYLFSqU6ji73X7T0m5mlSlTRl9//bVCQ0PVt29flSlTRmXKlNGECRNu+rrTp0+n+z5Snr/eje8lZfxRZt6LzWZTjx499PHHH2vKlCkqV66c7rnnnjSP/emnn9SiRQtJ12an/fDDD4qOjtbgwYMz3W5mZpOkfEFevnxZRYoUuelYmlu51c9LcnKyzp49m+VYJal06dKqU6eO6tSpo2bNmikqKkq9evXSf//7X/3666+SpOPHj8swDIWFhcnHx8dl27x5s7PbNCQkRBs2bFCNGjX0+uuvq3LlygoPD9ewYcNcxhllRVhYmHr06KEpU6Zo586d2rBhg3x9ffXiiy+6HNehQweFhIQ4u09Wrlyp48eP37IrqUePHjp58qRGjRqlbdu2Zarr6ezZszIMw+2/Dzc6fvy4du7cmeoaBQcHyzAM53W69957tWzZMiUmJuqJJ55Q8eLFVaVKlVQJYlZUrFhR/fr108cff6xDhw5p3LhxOn36tIYMGeKMUbp2nW6Mc8yYMTIMI8eXwLAGr/8fLJyTm4emD8x+yiHe3t5q2rSpVq1apSNHjtxyynPKH7Jjx46lOvbo0aMqXLhwtsXm5+cnSbpy5YrLAOYbx+1I0j333KN77rlHSUlJ2rJliyZOnKh+/fopLCxMnTt3TvP8hQoV0rFjx1LtTxnsmJ3v5Xrdu3fX0KFDNWXKFI0cOTLd4xYsWCAfHx+tWLHC+VlIytT6KCnSGnCdnmPHjqlv376qUaOGdu/erVdeeUXvvfdeptuUXH9ebnT06FF5eXmpQIECWY41PdWqVZNhGNq5c6cqVKigwoULy2az6bvvvktzMPz1+6pWraoFCxY4Xz979my9+eab8vf312uvvXbbsaW499571aJFCy1btkwnTpxwjnPy9/fXo48+qunTp+vYsWOaOXOmgoOD1bFjx5ueLyIiQs2aNdOIESNUvnx5NWzYMMOxFChQQF5eXqb8PlyvcOHC8vf3TzWm6PrnU7Rr107t2rXTlStXtHnzZkVFRalLly4qWbKkcxzT7bLZbHrppZf05ptvateuXS4xTJw4Md1ZW9dPuQfS4pmplkUMGjRIhmGod+/eaQ6sTUhI0BdffCFJuv/++yXJOdA3RXR0tPbu3aumTZtmW1wpM3hSFidLkRJLWry9vVWvXj3noNVt27ale2zTpk21du3aVDM2PvroIwUEBOTYNNNixYppwIABatu2rbp165bucTabTfny5XMZGHrp0iXNnTs31bHZVf1KSkrSo48+KpvNplWrVikqKkoTJ07UkiVLsnS+8uXLq1ixYpo3b57LjK34+HgtXrzYOSMqu6UsuJaSKLRp00aGYejvv/92VnWu39LqXrPZbKpevbreffdd5c+f3+VnKTOf9/Hjx52z/a6XlJSk3377TQEBAanWMOnZs6eSkpL09ttva+XKlercuXOGPqeXX35Zbdu2dVYVMiowMFD16tXTkiVLXN5XcnKyPv74YxUvXtwtaw61adNGf/zxhwoVKpTmdUpr/Sq73a7GjRtrzJgxkq7NXkvZL2W8cpRWQiddS+ri4uKcFatGjRopf/782rNnT5ox1qlTR76+vlmKIU/J4wOFqdTkoAYNGmjy5Mnq06ePateurWeffVaVK1dWQkKCtm/frmnTpqlKlSpq27atypcvr6eeekoTJ06Ul5eXWrZsqYMHD2rIkCGKiIjQSy+9lG1xtWrVSgULFlTPnj315ptvKl++fJo9e7YOHz7sctyUKVO0du1atW7dWiVKlNDly5ed/9Jr1qxZuucfNmyYVqxYofvuu09Dhw5VwYIF9cknn+jLL7/U2LFjFRISkm3v5UajR4++5TGtW7fWuHHj1KVLFz311FM6ffq03nnnnTQrDSnVhYULFzpXQ83KOJhhw4bpu+++01dffaUiRYro5Zdf1oYNG9SzZ0/VrFlTpUqVytT5vLy8NHbsWD322GNq06aNnn76aV25ckVvv/22zp07l6HP4VZ+++03bd68WdK1KfJff/21ZsyYoTp16ji79ho1aqSnnnpKPXr00JYtW3TvvfcqMDBQx44d0/fff6+qVavq2Wef1YoVKzRp0iS1b99epUuXlmEYWrJkic6dO6fmzZs726xatarWr1+vL774QkWLFlVwcLDKly+fZnxz587V1KlT1aVLF9WtW1chISE6cuSIPvzwQ+3evVtDhw51fgmmqFOnjqpVq6bx48fLMIwMdyW1aNHC2WWZWVFRUWrevLnuu+8+vfLKK/L19dWkSZO0a9cuzZ8/P1sqaLfSr18/LV68WPfee69eeuklVatWTcnJyTp06JC++uorvfzyy6pXr56GDh2qI0eOqGnTpipevLjOnTunCRMmyMfHx7lGUpkyZeTv769PPvlEFStWVFBQkMLDw53JyY2eeuopnTt3Tv/+979VpUoVeXt769dff9W7774rLy8v54zAoKAgTZw4Ud26ddOZM2fUoUMHhYaG6uTJk/r555918uRJTZ48WZKcv4MTJkxQt27d5OPjo/Lly9/WQpuwBpKaHNa7d2/dddddevfddzVmzBjFxMTIx8dH5cqVU5cuXfTcc885j508ebLKlCmjGTNm6IMPPlBISIgefPBBRUVFpTmGJqscDodWr16tfv366fHHH1f+/PnVq1cvtWzZ0mVqZo0aNfTVV19p2LBhiomJUVBQkKpUqaLly5ff9A98+fLltXHjRr3++uvq27evLl26pIoVK2rWrFmZWpk3p9x///2aOXOmxowZo7Zt26pYsWLq3bu3QkNDU33JjRgxQseOHVPv3r11/vx5RUZGZnqp+TVr1igqKkpDhgxxqbjNnj1bNWvWVKdOnfT999+n+gK+lS5duigwMFBRUVHq1KmTvL29Vb9+fa1bty5TXSTpef31153/PzAwUJGRkRoyZIj69+/vUuWaOnWq6tevr6lTp2rSpElKTk5WeHi4GjVq5BzMfueddyp//vwaO3asjh49Kl9fX5UvX16zZ892qapNmDBBffv2VefOnZ3TkNNbf6R169aKiYnRypUrNXnyZJ09e1bBwcGqVq2a5s6dm+406J49e+rFF19UpUqVVK9evdv+nG6lcePGWrt2rYYNG6bu3bsrOTlZ1atX1/Lly9WmTZscb1+6dv2+++47jR49WtOmTdOBAwec6041a9bMWampV6+etmzZooEDB+rkyZPKnz+/6tSpo7Vr16py5cqSpICAAM2cOVMjRoxQixYtlJCQoGHDhqW7Vs3zzz+vhQsXavr06fr7778VHx+vO+64Qw0aNNBHH33kUrl9/PHHVaJECY0dO1ZPP/20zp8/r9DQUNWoUcPlb0eTJk00aNAgzZkzR9OnT1dycrLWrVt303WN8gybzU2L73lmpcZmGCznCABAbhYXF6eQkBDZW4yVzcc/x9szEi7pylevKjY2NtO3uchJVGoAALAKbpMAAACQ+1GpAQDAKtw1M8lDx9RQqQEAAJZApQYAAKtgTA0AAEDul6srNcnJyTp69KiCg4PdsoAVAACZYRiGzp8/r/DwcJebzyJn5Oqk5ujRo6nuBA0AgKc5fPjwLe8BmC3y+EDhXJ3UpCyJ7Vupm2zemVuNFe6188tRZoeADIq9eHt3zQbw/y5cOK/763ALB3fJ1UlNSpeTzduXpMbDBXvQipO4uSRvkhogu7ltiAQDhQEAAHK/XF2pAQAA18njY2qo1AAAAEugUgMAgEXYbDb3jN+hUgMAAJBzqNQAAGARVGoAAAAsgKQGAABYAt1PAABYhe2fzR3teCAqNQAAwBKo1AAAYBEMFAYAALAAKjUAAFgElRoAAAALoFIDAIBFUKkBAACwACo1AABYBJUaAAAAC6BSAwCAVbCiMAAAQO5HUgMAACyBpAYAAItIGSjsji0zvv32W7Vt21bh4eGy2WxatmyZy/OGYWj48OEKDw+Xv7+/mjRpot27d2f6/ZPUAACAHBUfH6/q1avr/fffT/P5sWPHaty4cXr//fcVHR2tIkWKqHnz5jp//nym2mGgMAAAFmGzyU1Tuq/9T1xcnMtuu90uu92e6vCWLVuqZcuWaZ7KMAyNHz9egwcP1sMPPyxJmjNnjsLCwjRv3jw9/fTTGQ6LSg0AAMiSiIgIhYSEOLeoqKhMn+PAgQOKiYlRixYtnPvsdrsaN26sjRs3ZupcVGoAALAIm9y0+N4/pZrDhw/L4XA496ZVpbmVmJgYSVJYWJjL/rCwMP3111+ZOhdJDQAAyBKHw+GS1NyOG5MxwzAynaDR/QQAgEV46uynmylSpIik/6/YpDhx4kSq6s2tkNQAAADTlCpVSkWKFNGaNWuc+65evaoNGzaoYcOGmToX3U8AAFiFh94m4cKFC/r999+djw8cOKAdO3aoYMGCKlGihPr166dRo0bpzjvv1J133qlRo0YpICBAXbp0yVQ7JDUAACBHbdmyRffdd5/zcf/+/SVJ3bp10+zZs/Xqq6/q0qVL6tOnj86ePat69erpq6++UnBwcKbaIakBAMAqsnm8S3qMTLbRpEkTGYaR7vM2m03Dhw/X8OHDbysuxtQAAABLIKkBAACWQPcTAAAWkd3TrW/WjieiUgMAACyBSg0AABZBpQYAAMACqNQAAGAVHrr4nrtQqQEAAJZApQYAAItgTA0AAIAFUKkBAMAiqNQAAABYAJUaAAAsIq9XakhqTNKwZhk937WZqlcooaJ3hOixV6Zp5YadkqR83l5649m2at6osiKLFVLchcva8NOvGvH+csWcijU5cvz08x+atmCddu0/ohOn4zTlrR5qcU9Vs8PCDWYuWqe1G3fp4JETsvv6qHrFSL3Qo5VKFr/D7NBwHa4TspPp3U+TJk1SqVKl5Ofnp9q1a+u7774zOyS3CPC3a9f+v/Xq24tSP+fnq2oVIvT2jFVq0nWMnnh1usqUCNW8/z5tQqS40cXLV1WxTLiGv/iw2aHgJrb+8qcead1Ac/7bV5P/00uJScnq88aHunT5qtmh4TpcJ2QnUys1CxcuVL9+/TRp0iQ1atRIU6dOVcuWLbVnzx6VKFHCzNBy3Ncb9+jrjXvSfC4u/rIefu59l30D3/lUa+e8quJhBXTk+Fl3hIh0NKlXUU3qVTQ7DNzCB2/1dHk84qWOatrlLe35/YhqVyltUlS4Edcpe+X17idTKzXjxo1Tz5491atXL1WsWFHjx49XRESEJk+ebGZYHskR5K/k5GTFXrhkdihArnQ+/rIkKSQowORIcDNcJ9wO05Kaq1evauvWrWrRooXL/hYtWmjjxo1pvubKlSuKi4tz2fICu28+DevbTp/9b4vzFx5AxhmGoXHTV6hG5ZIqW7KI2eEgHVynbGBz4+aBTEtqTp06paSkJIWFhbnsDwsLU0xMTJqviYqKUkhIiHOLiIhwR6imyuftpRkje8jLy6ZXxqQefwPg1kZP/ly/HYxR1KuPmh0KboLrhNtl+kDhG/vlDMNIt69u0KBBio2NdW6HDx92R4imyeftpVlRPRUZXkj/eu59qjRAFoyZ/Lm+/XGPpkU9pbDC+c0OB+ngOmWPlDE17tg8kWkDhQsXLixvb+9UVZkTJ06kqt6ksNvtstvt7gjPdCkJTZkSd6jtM+/pbGy82SEBuYphGBoz5XOt27Rb06OeVrEiBc0OCWngOiE7mZbU+Pr6qnbt2lqzZo3+9a9/OfevWbNG7dq1Mysstwn091WpiP9fhyEyvJCqlCumc7EXdexUrOaM6aXqFSLU+aUp8va2KbRQsCTpbOxFJSQmmRU2JMVfvKK//j7lfHw45oz2/Pa3QhwBKhZWwMTIcL3Rk5Zp1YYdendINwX423XqzHlJUlCgn/zsPiZHhxRcp+yV12c/mTqlu3///uratavq1KmjBg0aaNq0aTp06JCeeeYZM8NyixoVI7Vi6ovOx6P6/1uSNG/FZo2etlKtGleTJH03b5DL69o8PUE/bPvNfYEilV/2HVaXlyY5H4/84HNJ0r8fqKu3BzEWwFN8unKzJKn3a1Nd9g/v11EPNa9jRkhIA9cJ2cnUpKZTp046ffq03nzzTR07dkxVqlTRypUrFRkZaWZYbvHDtt9UoO5z6T5/s+dgrvo1y+rP9ePMDgO3sO3LMWaHgAzgOmUvKjUm69Onj/r06WN2GAAAIJczPakBAADZxF1ryHhmocb8Kd0AAADZgaQGAABYAt1PAABYRF4fKEylBgAAWAKVGgAALIJKDQAAgAVQqQEAwCJsclOlxkPndFOpAQAAlkClBgAAi2BMDQAAgAVQqQEAwCq4TQIAAEDuR1IDAAAsge4nAAAsgoHCAAAAFkClBgAAi6BSAwAAYAFUagAAsAib7drmjnY8EZUaAABgCVRqAACwiGuVGneMqcnxJrKESg0AALAEKjUAAFiFm8bUcJsEAACAHESlBgAAi2CdGgAAAAsgqQEAAJZA9xMAABbB4nsAAAAWQKUGAACL8PKyycsr58sohhvayAoqNQAAwBKo1AAAYBGMqQEAALAAKjUAAFgEi+8BAABYAJUaAAAsgjE1AAAAFkClBgAAi2BMDQAAgAWQ1AAAAEug+wkAAIug+wkAAMACqNQAAGARTOkGAACwACo1AABYhE1uGlMjzyzVWCKpGTq6r/wCg80OAzdxLj7B7BCQQWfjr5odAjLgaPwls0NABly8cN7sEPIUSyQ1AACAMTWMqQEAAJZApQYAAItgnRoAAAALoFIDAIBFMKYGAADAAkhqAACAJdD9BACARTBQGAAAwAKo1AAAYBEMFAYAAMhBiYmJeuONN1SqVCn5+/urdOnSevPNN5WcnJyt7VCpAQDAIjx1TM2YMWM0ZcoUzZkzR5UrV9aWLVvUo0cPhYSE6MUXX8y2uEhqAABAjtq0aZPatWun1q1bS5JKliyp+fPna8uWLdnaDt1PAABYhe3/x9Xk5KZ/CjVxcXEu25UrV9IM6+6779Y333yj/fv3S5J+/vlnff/992rVqlW2vn0qNQAAIEsiIiJcHg8bNkzDhw9PddzAgQMVGxurChUqyNvbW0lJSRo5cqQeffTRbI2HpAYAAItw95iaw4cPy+FwOPfb7fY0j1+4cKE+/vhjzZs3T5UrV9aOHTvUr18/hYeHq1u3btkWF0kNAADIEofD4ZLUpGfAgAF67bXX1LlzZ0lS1apV9ddffykqKoqkBgAApOap69RcvHhRXl6uw3i9vb2Z0g0AAHKXtm3bauTIkSpRooQqV66s7du3a9y4cXryySeztR2SGgAAkKMmTpyoIUOGqE+fPjpx4oTCw8P19NNPa+jQodnaDkkNAAAW4amL7wUHB2v8+PEaP358zgT0D9apAQAAlkClBgAAi/DUgcLuQqUGAABYApUaAAAswlPH1LgLlRoAAGAJVGoAALAIKjUAAAAWQKUGAACLYPYTAACABVCpAQDAIhhTAwAAYAEkNQAAwBLofgIAwCIYKAwAAGABVGoAALAIBgoDAABYAJUaAAAswiY3janJ+SayhEoNAACwBCo1AABYhJfNJi83lGrc0UZWUKkBAACWQKUGAACLYJ0aAAAACyCpAQAAlkD3EwAAFsHiewAAABZApQYAAIvwsl3b3NGOJ6JSAwAALIFKjYf4ZtVGrf3fZpd9QcEBGvTWMyZFhLTMXLROazfu0sEjJ2T39VH1ipF6oUcrlSx+h9mh4QbLv/pJy7/6ScdPnpMkRRYPVdcOTVSvZjlzA8NNLV+xUZ8uXq8HmtfV412amx1O7mNz03gXD63UkNR4kNAihfRknw7Ox16eWt/Lw7b+8qcead1AlcsVV1JSst7/6H/q88aHWjzlZfn7+ZodHq5TuKBDvbu0UHiRgpKkrzZs19Cx8zR17LMqGRFmcnRIy59/HtW6DdsVERFqdijIpUztfvr222/Vtm1bhYeHy2azadmyZWaGYzovLy8FOwKdW2BQgNkh4QYfvNVTDzWvozKRRVSudLhGvNRRMSfPac/vR8wODTdoWKeC6tUqp4jwwooIL6yejzaXv5+v9vzGtfJEly9f1eRpy9WzeysFBviZHU6ulbL4njs2T2RqUhMfH6/q1avr/fffNzMMj3H61FmNHjpV77z5oRbM+VJnTp0zOyTcwvn4y5KkEBJQj5aUnKy1P+zU5StXValchNnhIA1z5v5P1auXUZXKpcwOBbmYqd1PLVu2VMuWLTN8/JUrV3TlyhXn47i4uJwIyxTFI4uqw2MPqvAdBXTh/EWt/+pHTZ2wQC++1k0Bgf5mh4c0GIahcdNXqEblkipbsojZ4SANfx6K0fODp+tqQqL8/Xw14pUuKlmcrg1Ps+nH3Tr4V4xGDOthdii5nu2f/9zRjifKVbOfoqKiFBIS4twiIqzzL67ylUqpSvVyKhJ+h8qWj9QTT/1LkrTtpz0mR4b0jJ78uX47GKOoVx81OxSkIyK8sKa93Ufvj3xKD7WoqzEfLNbBIyfMDgvXOX06Th/PW6NnnnpIvj4M88TtyVU/QYMGDVL//v2dj+Pi4iyV2FzP1+6jsKKFdfrkWbNDQRrGTP5c3/64Rx+OeUZhhfObHQ7S4ZMvn4oVKSRJKl+mmPb98beWrNyk/k+1MzkypDjw1zHFxV3U0BEznfuSkw3t239Ia77ZolnTB8rLK1f9+9tUeX2dmlyV1NjtdtntdrPDcIvExESdPH5GJUsXMzsUXMcwDI2Z8rnWbdqt6VFPq9g/M2uQOxiGlJCQZHYYuE7liiU16q1eLvumz/hS4UULqXWr+iQ0yJRcldRY2arPN6hC5dIKKeBQ/PmLWrfmR125fFU176psdmi4zuhJy7Rqww69O6SbAvztOnXmvCQpKNBPfnYfk6PD9T6ct0Z31bxToYVCdPHyFa374Rf9vPuAogY/YXZouI6/v10RN4xzstt9FBTkn2o/cCskNR4i9twFLfxopS7GX1JAkL9KRBbVMy89qgIFHWaHhut8uvLaAom9X5vqsn94v456qHkdM0JCOs7GXtDo9xfrzNnzCgzwU+nIMEUNfkJ1qpU1OzQgx+T1G1qamtRcuHBBv//+u/PxgQMHtGPHDhUsWFAlSpQwMTL369yttdkhIAO2fTnG7BCQQQOe/ZfZISCLBr/2uNkhIJcyNanZsmWL7rvvPufjlEHA3bp10+zZs02KCgCA3MldC+N5aKHG3KSmSZMmMgzDzBAAAIBFMKYGAACL8LLZ5OWGMoo72sgK5soBAABLoFIDAIBF5PUxNVRqAACAJVCpAQDAIvL6OjVUagAAgCVQqQEAwCIYUwMAAGABJDUAAMAS6H4CAMAiWHwPAADAAqjUAABgEbZ/Nne044mo1AAAAEugUgMAgEXk9cX3MpTUvPfeexk+4QsvvJDlYAAAALIqQ0nNu+++m6GT2Ww2khoAAEziZbu2uaMdT5ShpObAgQM5HQcAAMBtyfJA4atXr2rfvn1KTEzMzngAAEAWpYypccfmiTKd1Fy8eFE9e/ZUQECAKleurEOHDkm6NpZm9OjR2R4gAABARmQ6qRk0aJB+/vlnrV+/Xn5+fs79zZo108KFC7M1OAAAkDkpN7XMyc1TZXpK97Jly7Rw4ULVr1/fpfxUqVIl/fHHH9kaHAAAQEZlulJz8uRJhYaGptofHx/vsX1sAADA+jKd1NStW1dffvml83FKIjN9+nQ1aNAg+yIDAACZktcHCme6+ykqKkoPPvig9uzZo8TERE2YMEG7d+/Wpk2btGHDhpyIEQAA4JYyXalp2LChfvjhB128eFFlypTRV199pbCwMG3atEm1a9fOiRgBAEAGpCy+547NE2Xp3k9Vq1bVnDlzsjsWAACALMtSUpOUlKSlS5dq7969stlsqlixotq1a6d8+bg/JgAAZuGGlpm0a9cutWvXTjExMSpfvrwkaf/+/brjjju0fPlyVa1aNduDBAAAuJVMj6np1auXKleurCNHjmjbtm3atm2bDh8+rGrVqumpp57KiRgBAEAG2Ny4eaJMV2p+/vlnbdmyRQUKFHDuK1CggEaOHKm6detma3AAAAAZlelKTfny5XX8+PFU+0+cOKGyZctmS1AAACDzvGw2t22eKENJTVxcnHMbNWqUXnjhBX322Wc6cuSIjhw5os8++0z9+vXTmDFjcjpeAACANGWo+yl//vwuI50Nw9Ajjzzi3GcYhiSpbdu2SkpKyoEwAQDArbjrhpMeWqjJWFKzbt26nI4DAADgtmQoqWncuHFOxwEAAHBbsrxa3sWLF3Xo0CFdvXrVZX+1atVuOygAAJB5LL6XSSdPnlSPHj20atWqNJ9nTA0AADBDpqd09+vXT2fPntXmzZvl7++v1atXa86cObrzzju1fPnynIgRAABkQMpAYXdsnijTlZq1a9fq888/V926deXl5aXIyEg1b95cDodDUVFRat26dU7ECQAAcFOZrtTEx8crNDRUklSwYEGdPHlS0rU7d2/bti17owMAABnG4nuZVL58ee3bt0+SVKNGDU2dOlV///23pkyZoqJFi2Z7gAAAABmR6e6nfv366dixY5KkYcOG6YEHHtAnn3wiX19fzZ49O7vjAwAAGcTie5n02GOPOf9/zZo1dfDgQf36668qUaKEChcunK3BAQAAa/j77781cOBArVq1SpcuXVK5cuU0Y8YM1a5dO9vayPI6NSkCAgJUq1at7IgFAADcBk9dp+bs2bNq1KiR7rvvPq1atUqhoaH6448/lD9//myNK0NJTf/+/TN8wnHjxmU5GAAAYD1jxoxRRESEZs2a5dxXsmTJbG8nQ0nN9u3bM3Qys1YYXPLT38rnF2hK28iYP05fNjsEZNBz9SPNDgEZUKtUAbNDQAbExcWZHUKOuvH92e122e32VMctX75cDzzwgDp27KgNGzaoWLFi6tOnj3r37p2t8XBDSwAALMJLWZjWnMV2JCkiIsJl/7BhwzR8+PBUx//555+aPHmy+vfvr9dff10//fSTXnjhBdntdj3xxBPZFtdtj6kBAAB50+HDh+VwOJyP06rSSFJycrLq1KmjUaNGSbo20Wj37t2aPHkySQ0AAEjN3QOFHQ6HS1KTnqJFi6pSpUou+ypWrKjFixdna1zuqFIBAIA8rFGjRs6Fe1Ps379fkZHZO4aPSg0AABZhs0leHrj43ksvvaSGDRtq1KhReuSRR/TTTz9p2rRpmjZtWrbGRaUGAADkqLp162rp0qWaP3++qlSporfeekvjx493WdA3O2SpUjN37lxNmTJFBw4c0KZNmxQZGanx48erVKlSateuXbYGCAAAMsbLTZWarLTRpk0btWnTJvuDuU6mKzUpU7JatWqlc+fOKSkpSZKUP39+jR8/PrvjAwAAyJBMJzUTJ07U9OnTNXjwYHl7ezv316lTR7/88ku2BgcAADIuZfaTOzZPlOmk5sCBA6pZs2aq/Xa7XfHx8dkSFAAAQGZlOqkpVaqUduzYkWr/qlWrUs1BBwAA7pMypsYdmyfK9EDhAQMGqG/fvrp8+bIMw9BPP/2k+fPnKyoqSh9++GFOxAgAAHBLmU5qevToocTERL366qu6ePGiunTpomLFimnChAnq3LlzTsQIAABwS1ma0t27d2/17t1bp06dUnJyskJDQ7M7LgAAkEk2W+YXxstqO57otlYULly4cHbFAQAAcFsyndSUKlXqplO5/vzzz9sKCAAAZI2XzSYvN5RR3NFGVmQ6qenXr5/L44SEBG3fvl2rV6/WgAEDsisuAACATMl0UvPiiy+muf+DDz7Qli1bbjsgAACQNV5yz00dPfXGkdkWV8uWLbV48eLsOh0AAECm3NZA4et99tlnKliwYHadDgAAZBKznzKpZs2aLgOFDcNQTEyMTp48qUmTJmVrcAAAABmV6aSmffv2Lo+9vLx0xx13qEmTJqpQoUJ2xQUAADLJS26a/STPLNVkKqlJTExUyZIl9cADD6hIkSI5FRMAAECmZWqgcL58+fTss8/qypUrORUPAADIopQxNe7YPFGmZz/Vq1dP27dvz4lYAAAAsizTY2r69Omjl19+WUeOHFHt2rUVGBjo8ny1atWyLTgAAICMynBS8+STT2r8+PHq1KmTJOmFF15wPmez2WQYhmw2m5KSkrI/SgAAcEtetmubO9rxRBlOaubMmaPRo0frwIEDORkPAABAlmQ4qTEMQ5IUGRmZY8EAAICss9ncc7NJSwwUvtnduQEAAMyUqYHC5cqVu2Vic+bMmdsKCAAAZA23SciEESNGKCQkJKdiAQAAyLJMJTWdO3dWaGhoTsUCAABuQ16f/ZThMTWMpwEAAJ4s07OfAACAZ7L985872vFEGU5qkpOTczIOAACA25Lp2yQAAADPxJgaAAAACyCpAQAAlkD3EwAAFkH3EwAAgAVQqQEAwCJsNptb1pXz1LXrqNQAAABLoFIDAIBFMKYGAADAAqjUAABgETbbtc0d7XgiKjUAAMASqNQAAGARXjabvNxQRnFHG1lBUuMhvG1S94Yl1axSqAoG+Op0/FWt3n1cczf9Je6P7lkcfvnUplKoKoQGycfLSyfjr2rRjqM6EnvZ7NBwnZmL1mntxl06eOSE7L4+ql4xUi/0aKWSxe8wOzSk4cNPv9XEj7/R8VOxqlC6qEb1/7ca1ixrdljIZUztfoqKilLdunUVHBys0NBQtW/fXvv27TMzJNM8elcJPVQ9XBO++V3dZkVr6rd/qnPd4nq4VjGzQ8N1/H289PzdJZWULE3ffEhj1/2hL3Yf16WEJLNDww22/vKnHmndQHP+21eT/9NLiUnJ6vPGh7p0+arZoeEGS77aqtfHLdbLPR7Qho9fU4MaZfTIi5N0OOaM2aHlOimzn9yxeSJTk5oNGzaob9++2rx5s9asWaPExES1aNFC8fHxZoZlisrhDn3/xylt/vOMYuKuaMP+U4o+eFblw4LNDg3Xub9sYZ27lKiFO47q8LnLOnspQb+ditfpiwlmh4YbfPBWTz3UvI7KRBZRudLhGvFSR8WcPKc9vx8xOzTcYNK8tXq8XQM90b6hypcqoqiXO6hYWAHN/Ow7s0NDLmNq99Pq1atdHs+aNUuhoaHaunWr7r33XpOiMscvf8fqoerhKl7AX0fOXlKZOwJVtViI3l/3u9mh4TqVigRr34kLeqJOcZUuFKC4ywn64cBZ/XjonNmh4RbOx1/rHgwJCjA5ElzvakKidvx6WP26tXDZf1+9ivpp5wGTokJu5VFjamJjYyVJBQsWTPP5K1eu6MqVK87HcXFxbonLHeb9dFiB9nz66Mm6Sk425OVl04ffHdDaX0+aHRquUyjARw1LFtCGP87om/2nFFHAT/+qWkSJyYa2Hok1OzykwzAMjZu+QjUql1TZkkXMDgfXOX3ugpKSknVHQdeq9B2FgnXitHX+xruNm6Z0y0O7nzwmqTEMQ/3799fdd9+tKlWqpHlMVFSURowY4ebI3OP+8neoecVQ/WfFXh04fVFlQwP13H1ldTr+qv63+7jZ4eEfNptNR85d0qpfT0iS/o67rCLBdjUsWYCkxoONnvy5fjsYo5lvP2N2KEjHjV/EhmF47P2F4Lk8Zp2a5557Tjt37tT8+fPTPWbQoEGKjY11bocPH3ZjhDnrmcalNe+nw1q776QOnIrXmj0n9NnWI3rsrhJmh4brxF1O0PHzV1z2Hb9wVQX8fUyKCLcyZvLn+vbHPZoW9ZTCCuc3OxzcoFD+IHl7e+nE6fMu+0+duZCqeoNb85LNbZsn8oik5vnnn9fy5cu1bt06FS9ePN3j7Ha7HA6Hy2YVdh9vJRuuk7eTkg2PXbUxrzp45pLuCLK77Lsj0FdnLzFQ2NMYhqHRk5dp7aZdmjrqKRUrkna3Nszl65NPNSpEaN2Pv7rsX//Tr7qrWimTokJuZWpSYxiGnnvuOS1ZskRr165VqVJ59wd40x+n1bV+pOqXLqgiDrvuLltIj9Qpru9+P2V2aLjOt3+eVmQBfzW9s7AKBfqoZjGH6kcW0A8HmHrqaUZPWqaV67Zr1IBHFeBv16kz53XqzHldvkIC6mn6dLlfcz/fqI+Xb9K+AzF6fdxiHYk5ox7/vsfs0HKdlNskuGPzRKaOqenbt6/mzZunzz//XMHBwYqJiZEkhYSEyN/f38zQ3G7CN7+r590l1a/ZnSrg76NT8Vf1xc/HNGfTX2aHhuscPndZs6IPq3XFUDUvV1hnLibo810x2vY3Axo9zacrN0uSer821WX/8H4d9VDzOmaEhHQ83KK2zsTGa+yHq3T8VJwqlimqheP7qERRqmvIHJthGKYtWJveILBZs2ape/fut3x9XFycQkJCVHvYl8rnF5jN0SE71S7HKq65xXP1I80OARlQKpS/eblBXFycwgqFKDY2NkeHTKR8H45bs1P+gTk/FulS/Hn1b14tx99XZplaqTExnwIAABbjMVO6AQDA7cnrN7T0iNlPAAAAt4tKDQAAFuGumUkeWqihUgMAAKyBpAYAAFgC3U8AAFiEl9w0UJjbJAAAAOQcKjUAAFgEA4UBAAAsgEoNAAAW4SX3VCs8tSLiqXEBAABkCpUaAAAswmazpXuz6OxuxxNRqQEAAJZApQYAAIuw/bO5ox1PRKUGAABYAkkNAACwBLqfAACwCC+bm26TwEBhAACAnEOlBgAAC/HMGop7UKkBAACWQKUGAACL4IaWAAAAFkClBgAAi+A2CQAAABZApQYAAIvwknuqFZ5aEfHUuAAAADKFSg0AABbBmBoAAAALIKkBAACWQFIDAIBF2Ny4ZVVUVJRsNpv69et3G2dJG0kNAABwi+joaE2bNk3VqlXLkfOT1AAAYBEpA4XdsUlSXFycy3blypV0Y7tw4YIee+wxTZ8+XQUKFMiR909SAwAAsiQiIkIhISHOLSoqKt1j+/btq9atW6tZs2Y5Fg9TugEAsAh3L753+PBhORwO53673Z7m8QsWLNC2bdsUHR2do3GR1AAAgCxxOBwuSU1aDh8+rBdffFFfffWV/Pz8cjQekhoAACzCExff27p1q06cOKHatWs79yUlJenbb7/V+++/rytXrsjb2ztb4iKpAQAAOaZp06b65ZdfXPb16NFDFSpU0MCBA7MtoZFIagAAsIzbXUMmM+1kVHBwsKpUqeKyLzAwUIUKFUq1/3Yx+wkAAFgClRoAACzCZru2uaOd27F+/fpsieNGVGoAAIAlkNQAAABLoPsJAACL8JJNXm4YKuyONrKCSg0AALAEKjUAAFhEbhkonFMskdQ8fFcx+QUGmx0GbqLlnWFmhwBYyopdR80OARlw8cJ5s0PIUyyR1AAAAMn2z3/uaMcTMaYGAABYApUaAAAsIq+PqaFSAwAALIFKDQAAFmFz0zo1jKkBAADIQVRqAACwCMbUAAAAWABJDQAAsAS6nwAAsAi6nwAAACyASg0AABbBbRIAAAAsgEoNAAAW4WW7trmjHU9EpQYAAFgClRoAACyCMTUAAAAWQKUGAACLYJ0aAAAAC6BSAwCARdjknvEuHlqooVIDAACsgaQGAABYAt1PAABYBIvvAQAAWACVGgAALILF9wAAACyASg0AABbB4nsAAAAWQKUGAACLsMk9C+N5aKGGSg0AALAGKjUAAFiEl2zycsOAFy8PrdVQqQEAAJZAUgMAACyB7icAACyCgcIAAAAWQKUGAACryOOlGio1AADAEqjUAABgEdzQEgAAwAKo1AAAYBVuuqGlhxZqqNQAAABroFIDAIBF5PHJT1RqAACANVCpAQDAKvJ4qYZKDQAAsASSGgAAYAl0PwEAYBEsvgcAAGABVGo8xDerNmrt/za77AsKDtCgt54xKSKkZeaidVq7cZcOHjkhu6+PqleM1As9Wqlk8TvMDg034FrlTstXbNSni9frgeZ19XiX5maHk+vY3LT4nlsW+MsCkhoPElqkkJ7s08H52MvLQ39q8rCtv/ypR1o3UOVyxZWUlKz3P/qf+rzxoRZPeVn+fr5mh4frcK1ynz//PKp1G7YrIiLU7FCQS5na/TR58mRVq1ZNDodDDodDDRo00KpVq8wMyVReXl4KdgQ6t8CgALNDwg0+eKunHmpeR2Uii6hc6XCNeKmjYk6e057fj5gdGm7AtcpdLl++qsnTlqtn91YKDPAzO5xcy+bGzROZWqkpXry4Ro8erbJly0qS5syZo3bt2mn79u2qXLmymaGZ4vSpsxo9dKry5fNW8ciiatG6kQoWzm92WLiJ8/GXJUkhJKAej2vl2ebM/Z+qVy+jKpVL6fMvfjA7HORSpiY1bdu2dXk8cuRITZ48WZs3b04zqbly5YquXLnifBwXF5fjMbpL8cii6vDYgyp8RwFdOH9R67/6UVMnLNCLr3VTQKC/2eEhDYZhaNz0FapRuaTKlixidji4Ca6VZ9v0424d/CtGI4b1MDuU3I/F9zxDUlKSFixYoPj4eDVo0CDNY6KiohQSEuLcIiIi3BxlzilfqZSqVC+nIuF3qGz5SD3x1L8kSdt+2mNyZEjP6Mmf67eDMYp69VGzQ8EtcK081+nTcfp43ho989RD8vVhmCduj+k/Qb/88osaNGigy5cvKygoSEuXLlWlSpXSPHbQoEHq37+/83FcXJylEpvr+dp9FFa0sE6fPGt2KEjDmMmf69sf9+jDMc8ojC5Cj8a18mwH/jqmuLiLGjpipnNfcrKhffsPac03WzRr+kB5eXnMv789Xl5fp8b0pKZ8+fLasWOHzp07p8WLF6tbt27asGFDmomN3W6X3W43IUr3S0xM1MnjZ1SydDGzQ8F1DMPQmCmfa92m3Zoe9bSKFSlodkhIB9cqd6hcsaRGvdXLZd/0GV8qvGghtW5Vn4QGmWJ6UuPr6+scKFynTh1FR0drwoQJmjp1qsmRudeqzzeoQuXSCingUPz5i1q35kdduXxVNe/KewOmPdnoScu0asMOvTukmwL87Tp15rwkKSjQT352H5Ojw/W4VrmDv79dEcVdp3Db7T4KCvJPtR+3xjo1HsYwDJfBwHlF7LkLWvjRSl2Mv6SAIH+ViCyqZ156VAUKOswODdf5dOW1BRJ7v+aadA/v11EPNa9jRkhIB9cKyHtMTWpef/11tWzZUhERETp//rwWLFig9evXa/Xq1WaGZYrO3VqbHQIyYNuXY8wOARnEtcq9Br/2uNkhIJcyNak5fvy4unbtqmPHjikkJETVqlXT6tWr1bw5S2MDAJBZeXxGt7lJzYwZM8xsHgAAWIjHjakBAABZlMdLNcyVAwAAlkClBgAAi8jri+9RqQEAAJZApQYAAIvI64vvUakBAACWQKUGAACLyOOTn6jUAAAAa6BSAwCAVeTxUg2VGgAAYAkkNQAAwBLofgIAwCJYfA8AAMACqNQAAGARLL4HAACQg6KiolS3bl0FBwcrNDRU7du31759+7K9HZIaAAAswubGLTM2bNigvn37avPmzVqzZo0SExPVokULxcfH38a7TY3uJwAAkKNWr17t8njWrFkKDQ3V1q1bde+992ZbOyQ1AABYhZsX34uLi3PZbbfbZbfbb/ny2NhYSVLBggWzNSy6nwAAQJZEREQoJCTEuUVFRd3yNYZhqH///rr77rtVpUqVbI2HSg0AABbh7nVqDh8+LIfD4dyfkSrNc889p507d+r777/P9rhIagAAQJY4HA6XpOZWnn/+eS1fvlzffvutihcvnu3xkNQAAGARnrpOjWEYev7557V06VKtX79epUqVypG4SGoAAECO6tu3r+bNm6fPP/9cwcHBiomJkSSFhITI398/29phoDAAAMhRkydPVmxsrJo0aaKiRYs6t4ULF2ZrO1RqAACwCDfP6M4wwzByJI4bUakBAACWQKUGAACr8NRSjZtQqQEAAJZApQYAAItw9+J7noZKDQAAsAQqNQAAWIWbFt/z0EINlRoAAGANVGoAALCIPD75iUoNAACwBio1AABYRR4v1VCpAQAAlkBSAwAALIHuJwAALILF9wAAACyASg0AABZhc9Pie25Z4C8LqNQAAABLoFIDAIBF5PEZ3VRqAACANVCpAQDAKvJ4qSZXJzWGYUiSLl+8YHIkuJUL5/3NDgGwlIsXzpsdAjLgUvy176eU7yvkrFyd1Jw/f+2X+q2Od5scCW5lsNkBAICJzp8/r5CQkBxvJ6+vU5Ork5rw8HAdPnxYwcHBsnnq/LJMiouLU0REhA4fPiyHw2F2OLgJrlXuwHXKHax6nQzD0Pnz5xUeHm52KHlCrk5qvLy8VLx4cbPDyBEOh8NSv9hWxrXKHbhOuYMVr5M7KjS4JlcnNQAA4P/Z5KbF93K+iSxhSjcAALAEKjUexm63a9iwYbLb7WaHglvgWuUOXKfcgeuUPfL4jG7ZDOaZAQCQq8XFxSkkJES7D5xQsBvGJJ2Pi1PlUqGKjY31qDFQVGoAALAIbmgJAABgAVRqAACwjLw9qoZKDQAAsAQqNQAAWARjagAAACyASo2bJCYmyjAM+fj4mB0KYCmGYVjm3m/A7crbI2pIatxiz549GjFihI4ePaqyZcuqRYsWevTRR80OC2lISkqSt7e32WHgFuLj45WcnCzDMDxqjQy4OnPmjE6cOCFvb29FRkbK19fX7JBgcXQ/5bD9+/erYcOG8vX1VfPmzfXnn3/q7bffVo8ePcwODTfYv3+/xo8fr2PHjpkdCm5iz549evjhh9W4cWNVrFhRn3zyiaRrFRt4jl27dqlZs2Z65JFHVLVqVY0dO1ZJSUlmhwWLI6nJQYZh6KOPPlLz5s01d+5cDR06VKtWrVLPnj21detWderUyewQ8Y/ff/9dDRo00IABAzRx4kSdOnXK7JCQhj179ujee+9V5cqVNWDAAHXu3Fk9evTQjh076ILyIHv27FGTJk3UtGlTLViwQCNHjtTQoUN19OhRs0OzvJSBwu7YPBHdTznIZrPp77//VkxMjHNfQECAnnzySfn5+emDDz7QoEGDFBUVZWKUiI+PV1RUlB566CHVqVNHzz//vBITE/Xqq6+qcOHCZoeHf5w5c0YvvfSSHnvsMY0bN06S9Oijj2r79u2aNWuWJkyYwPgaD3Dq1Ck9++yzevzxx/X2229LkipWrKivv/5aR44c0enTp1WoUCFFRESYHCmsiKQmh6T8ca1Vq5b27dunX3/9VRUqVJAk+fv7q2PHjtq/f7/WrVunEydOKDQ01OSI8y4vLy/Vrl1bhQoVUqdOnXTHHXeoc+fOkkRi40ESEhJ07tw5dejQQZKUnJwsLy8vlS5dWqdPn5YkEhoPYLPZ9OCDDzqvkyT95z//0f/+9z/FxMTo1KlTqly5st544w3dfffdJkZqTbZ//nNHO56I7qcckvLHtVWrVvrtt980duxYnT9/3vm8w+FQv379FB0drY0bN5oVJnQtyezWrZuzO/CRRx7R/Pnz9c4772jMmDHOL8zk5GQdOHDAzFDztLCwMH388ce65557JMk5PqNYsWLy8nL9U3bhwgW3x4drChUqpOeee0533nmnJGnBggUaNmyY5s+fr2+++UaffPKJzp49q2+++cbkSGFFVGpyWJkyZbRo0SK1bNlSAQEBGj58uPNf/r6+vqpZs6by589vbpBQYGCgpGtflF5eXurUqZMMw1CXLl1ks9nUr18/vfPOO/rrr780d+5cBQQEmBxx3pTyRZmcnOxcHiEpKUnHjx93HhMVFSW73a4XXnhB+fLxJ84MwcHBzv/foEEDbdmyRbVq1ZIk3XvvvQoLC9PWrVvNCs/a8vicbn7j3eC+++7Tp59+qo4dO+ro0aPq2LGjqlWrprlz5+rIkSMqU6aM2SHiH97e3jIMQ8nJyercubNsNpu6du2q5cuX648//lB0dDQJjQfw8vJydvHabDbnNPyhQ4fqP//5j7Zv305C4yEiIyMVGRkp6Vq3/NWrVxUUFKQqVaqYHBmsiO4nN2nbtq02btyoM2fO6LXXXtNDDz2kZcuWadWqVQyY8zApX5SGYahTp0665557dPLkSW3btk01atQwOzz8I2UKt7e3tyIiIvTOO+9o7Nix2rJli6pXr25ydEiLzWbTyJEj9cMPP6hjx45mh2NJNjdunoh/yrhRrVq1tHz5cp05c0YXLlxQkSJFGITqoWw2m5KSkjRgwACtW7dOO3bsUNWqVc0OC9dJGUfj4+Oj6dOny+Fw6Pvvv3d2c8CzfPbZZ1q/fr0WLFigNWvWOLsSgexEpcbNHA6HSpYsqSpVqpDQ5AKVK1fWtm3bVK1aNbNDQToeeOABSdLGjRtVp04dk6NBeipWrKiTJ0/q22+/Vc2aNc0Ox7Ly+jo1NoNlOIF0se5J7hAfH+8c7A3PlZCQwP3vckhcXJxCQkL0+5FTCnbDrUPOx8WpbPHCio2N9ahbldD9BNwECU3uQEKTO5DQ5DzWqQEAALAAkhoAAGAJdD8BAGAVeXzxPSo1AADAEqjUAABgEXm8UEOlBgAAWANJDZDLDB8+3OV2Dd27d1f79u3dHsfBgwdls9m0Y8eOdI8pWbKkxo8fn+Fzzp49O1tu8Gqz2bRs2bLbPg+Q2+T1xfdIaoBs0L17d+c9o3x8fFS6dGm98sorio+Pz/G2J0yYoNmzZ2fo2IwkIgCQWzGmBsgmDz74oGbNmqWEhAR999136tWrl+Lj4zV58uRUx2bnyqohISHZch4AVuCexfc8dVQNlRogm9jtdhUpUkQRERHq0qWLHnvsMWcXSEqX0cyZM1W6dGnZ7XYZhqHY2Fg99dRTCg0NlcPh0P3336+ff/7Z5byjR49WWFiYgoOD1bNnT12+fNnl+Ru7n5KTkzVmzBiVLVtWdrtdJUqU0MiRIyVJpUqVkiTVrFlTNptNTZo0cb5u1qxZqlixovz8/FShQgVNmjTJpZ2ffvpJNWvWlJ+fn+rUqaPt27dn+jMaN26cqlatqsDAQEVERKhPnz66cOFCquOWLVumcuXKyc/PT82bN9fhw4ddnv/iiy9Uu3Zt+fn5qXTp0hoxYoQSExMzHQ8AayGpAXKIv7+/EhISnI9///13LVq0SIsXL3Z2/7Ru3VoxMTFauXKltm7dqlq1aqlp06Y6c+aMJGnRokUaNmyYRo4cqS1btqho0aKpko0bDRo0SGPGjNGQIUO0Z88ezZs3T2FhYZKuJSaS9PXXX+vYsWNasmSJJGn69OkaPHiwRo4cqb1792rUqFEaMmSI5syZI+navZXatGmj8uXLa+vWrRo+fLheeeWVTH8mXl5eeu+997Rr1y7NmTNHa9eu1auvvupyzMWLFzVy5EjNmTNHP/zwg+Li4tS5c2fn8//73//0+OOP64UXXtCePXs0depUzZ4925m4AXlZXh9TIwPAbevWrZvRrl075+Mff/zRKFSokPHII48YhmEYw4YNM3x8fIwTJ044j/nmm28Mh8NhXL582eVcZcqUMaZOnWoYhmE0aNDAeOaZZ1yer1evnlG9evU0246LizPsdrsxffr0NOM8cOCAIcnYvn27y/6IiAhj3rx5Lvveeusto0GDBoZhGMbUqVONggULGvHx8c7nJ0+enOa5rhcZGWm8++676T6/aNEio1ChQs7Hs2bNMiQZmzdvdu7bu3evIcn48ccfDcMwjHvuuccYNWqUy3nmzp1rFC1a1PlYkrF06dJ02wWsJjY21pBkHDx2xjgTn5jj28FjZwxJRmxsrNlv3QVjaoBssmLFCgUFBSkxMVEJCQlq166dJk6c6Hw+MjJSd9xxh/Px1q1bdeHCBRUqVMjlPJcuXdIff/whSdq7d6+eeeYZl+cbNGigdevWpRnD3r17deXKFTVt2jTDcZ88eVKHDx9Wz5491bt3b+f+xMRE53idvXv3qnr16goICHCJI7PWrVunUaNGac+ePYqLi1NiYqIuX77scpftfPnyqU6dOs7XVKhQQfnz59fevXt11113aevWrYqOjnapzCQlJeny5cu6ePGiS4wA8haSGiCb3HfffZo8ebJ8fHwUHh6eaiDwjXeSTk5OVtGiRbV+/fpU58rqtGZ/f/9MvyY5OVnStS6oevXquTzn7e0tSTIMI0vxXO+vv/5Sq1at9Mwzz+itt95SwYIF9f3336tnz54u3XRS2ndHT9mXnJysESNG6OGHH051jJ+f323HCSD3IqkBsklgYKDKli2b4eNr1aqlmJgY5cuXTyVLlkzzmIoVK2rz5s164oknnPs2b96c7jnvvPNO+fv765tvvlGvXr1SPe/r6yvpWmUjRVhYmIoVK6Y///xTjz32WJrnrVSpkubOnatLly45E6ebxZGWLVu2KDExUf/973/l5XVtON+iRYtSHZeYmKgtW7borrvukiTt27dP586dU4UKFSRd+9z27duXqc8aQN5AUgOYpFmzZmrQoIHat2+vMWPGqHz58jp69KhWrlyp9u3bq06dOnrxxRfVrVs31alTR3fffbc++eQT7d69W6VLl07znH5+fho4cKBeffVV+fr6qlGjRjp58qR2796tnj17KjQ0VP7+/lq9erWKFy8uPz8/hYSEaPjw4XrhhRfkcDjUsmVLXblyRVu2bNHZs2fVv39/denSRYMHD1bPnj31xhtv6ODBg3rnnXcy9X7LlCmjxMRETZw4UW3bttUPP/ygKVOmpDrOx8dHzz//vN577z35+PjoueeeU/369Z1JztChQ9WmTRtFRESoY8eO8vLy0s6dO/XLL7/oP//5T+YvBGAh7hrE66kDhZn9BJjEZrNp5cqVuvfee/Xkk0+qXLly6ty5sw4ePOicrdSpUycNHTpUAwcOVO3atfXXX3/p2Wefvel5hwwZopdffllDhw5VxYoV1alTJ504cULStfEq7733nqZOnarw8HC1a9dOktSrVy99+OGHmj17tqpWrarGjRtr9uzZzingQUFB+uKLL7Rnzx7VrFlTgwcP1pgxYzL1fmvUqKFx48ZpzJgxqlKlij755BNFRUWlOi4gIEADBw5Uly5d1KBBA/n7+2vBggXO5x944AGtWLFCa9asUd26dVW/fn2NGzdOkZGRmYoHgPXYjOzoLAcAAKaJi4tTSEiIDsWclcPhcEt7JYoUUGxsrFvayygqNQAAwBIYUwMAgEUwpgYAAMACqNQAAGARNrnnVpMeWqihUgMAAKyBSg0AAFaRx0s1VGoAAIAlUKkBAMAibP/85452PBGVGgAAYAkkNQAAwBLofgIAwCJYfA8AAMACqNQAAGAReXxGN5UaAABgDVRqAACwijxeqqFSAwAALIFKDQAAFsHiewAAAG4wadIklSpVSn5+fqpdu7a+++67bD0/SQ0AABaRsk6NO7bMWrhwofr166fBgwdr+/btuueee9SyZUsdOnQo+96/YRhGtp0NAAC4XVxcnEJCQnT8dKwcDodb2gsrFKLY2Iy3V69ePdWqVUuTJ0927qtYsaLat2+vqKiobImLMTUAAFhEXFycW9u5sT273S673Z7q+KtXr2rr1q167bXXXPa3aNFCGzduzLa4SGoAAMjlfH19VaRIEd1ZKsJtbQYFBSkiwrW9YcOGafjw4amOPXXqlJKSkhQWFuayPywsTDExMdkWE0kNAAC5nJ+fnw4cOKCrV6+6rU3DMGS7YXBNWlWa6914fFrnuB0kNQAAWICfn5/8/PzMDiNNhQsXlre3d6qqzIkTJ1JVb24Hs58AAECO8vX1Ve3atbVmzRqX/WvWrFHDhg2zrR0qNQAAIMf1799fXbt2VZ06ddSgQQNNmzZNhw4d0jPPPJNtbZDUAACAHNepUyedPn1ab775po4dO6YqVapo5cqVioyMzLY2WKcGAABYAmNqAACAJZDUAAAASyCpAQAAlkBSAwAALIGkBgAAWAJJDQAAsASSGgAAYAkkNQAAwBJIagAAgCWQ1AAAAEsgqQEAAJbwf7Hjk0bS6/usAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the previous cell with GridSearchCV ran successfully and clf_simple exists\n",
    "\n",
    "print(\"Evaluating the best SVM model found by GridSearchCV on the test set...\")\n",
    "\n",
    "# 1. Get the best estimator found by GridSearchCV\n",
    "try:\n",
    "    best_svm = clf_simple.best_estimator_\n",
    "    print(\"\\nBest SVM Estimator retrieved:\")\n",
    "    print(best_svm)\n",
    "\n",
    "    # 2. Make predictions on the test set\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "\n",
    "    # 3. Calculate and report the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\n--- Accuracy ---\")\n",
    "    print(f\"Accuracy of the best SVM on the test set: {accuracy:.4f} ({accuracy * 100:.2f}%)\")\n",
    "\n",
    "    # 4. Calculate and display the confusion matrix\n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Use ConfusionMatrixDisplay for a nice plot\n",
    "    # Ensure the labels match the classes the SVM was trained on (should be 0, 1, 2, 3, 4)\n",
    "    try:\n",
    "        display_labels = best_svm.classes_\n",
    "    except AttributeError:\n",
    "        # Fallback if .classes_ isn't available for some reason\n",
    "        display_labels = sorted(np.unique(y_test))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(6, 6)) # Adjust size if needed\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "    plt.title(\"Confusion Matrix for Best SVM on Test Set\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERROR: 'clf_simple' object not found.\")\n",
    "    print(\"Please ensure the previous cell containing GridSearchCV ran successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf396ba-1d88-4d14-8771-210dc41fcbcf",
   "metadata": {},
   "source": [
    "Does SVM classifier work much better than your percetron?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81488c96-0326-408f-aed9-d956ee068d65",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> Yes, 40% accuracy vs 24%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5af1a-7950-4356-bc42-29c41b31c03d",
   "metadata": {},
   "source": [
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "---\n",
    "### 3.2 PCA \n",
    "\n",
    "Although we only have 11 feature variables in the dataset, let's examine how much principal component analysis (PCA) can accelerate the classification. We will increase the PCA components from 1 to 11. For each case, we will perform a GridSearch and use test set to examine the accuracy. \n",
    "\n",
    "* Write a code to loop over n_components = 1 through 11. **4 pt**\n",
    "* Record the accuracy of each case and plot the profile of accuracy versus n_components. In the mean time, record the computer run times and plot the profile of time versus n_components. **2 pt**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7c31b-cc0f-4ce7-9156-cc1207b26186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f02dd4-9ad8-416f-8324-cede07489a0a",
   "metadata": {},
   "source": [
    "Please answer the following questions. \n",
    "* How is the overall accuracy of this SVM classifier?  **1 pt**\n",
    "* If the performance is not good, what do you think the cause is? **2 pt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5f56b-173e-4013-9ccb-cd717aaf2524",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> Put your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ccaefe-5020-42f3-8d1b-2359bcdb535d",
   "metadata": {},
   "source": [
    "* Describe the curves of time vs n_components and accuracy vs n_components. **1 pt**\n",
    "* Explain why the curves behave as they are in the figures **2 pt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43066ffe-1bdb-4c50-b4dd-ecec5287fc64",
   "metadata": {},
   "source": [
    "<font size=6 color=\"#009600\">&#9998;</font> Put your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10fcb2-8d8b-4e2f-a9fe-5b998e646114",
   "metadata": {},
   "source": [
    "### &#128721; STOP (1 Point)\n",
    "**Pause, save and commit your FINAL changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## Assignment wrap-up\n",
    "\n",
    "\n",
    "Please fill out the form that appears when you run the code below.  **You must completely fill this out in order to receive credit for the assignment!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa2c83-4226-47d8-ad62-0a15001b3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\n",
    "\"\"\"\n",
    "<iframe \n",
    "\tsrc=\"https://forms.office.com/r/mB0YjLYvAA\" \n",
    "\twidth=\"800px\" \n",
    "\theight=\"600px\" \n",
    "\tframeborder=\"0\" \n",
    "\tmarginheight=\"0\" \n",
    "\tmarginwidth=\"0\">\n",
    "\tLoading...\n",
    "</iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f1ca9-1cce-4437-a38d-163b31945d70",
   "metadata": {},
   "source": [
    "## Congratulations, you're done!\n",
    "\n",
    "&#169; Copyright 2025,  Department of Computational Mathematics, Science and Engineering at Michigan State University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ef267-8dfb-4e1c-86b7-d4c4d42d6bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
